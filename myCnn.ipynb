{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 基于卷积神经网络的手写英文字母识别系统研究",
   "id": "553978cdf843cfcb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T13:50:05.868260Z",
     "start_time": "2025-04-22T13:50:01.795571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from myCnn.cnnWithAttention.utils import *\n",
    "from myCnn.cnnWithAttention.attentionStructure import *\n",
    "from myCnn.cnnWithAttention.train_my_cnn import *\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "acd8cdf4eee54e5f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 基本参数设置",
   "id": "2588026462704b14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T13:50:05.881103Z",
     "start_time": "2025-04-22T13:50:05.874267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ROOT_DIR = \"emnist_png_balanced\"  # 数据集路径\n",
    "BATCH_SIZE = 256  # 批大小\n",
    "EPOCH = 500  # 训练轮数\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")# 设备选择\n",
    "LR = 1e-4  # 学习率"
   ],
   "id": "52a37f0c142830aa",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 加入数据增强",
   "id": "ba0f318b695458e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T13:50:06.267876Z",
     "start_time": "2025-04-22T13:50:06.001502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = AlbumentationsTransform()  # 使用数据增强\n",
    "\n",
    "train_loader, val_loader, test_loader, full_dataset = split_dataset(\n",
    "    root_dir=ROOT_DIR,\n",
    "    transform=transform,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# 打印数据集大小\n",
    "print(f\"训练集大小: {len(train_loader.dataset)}\")\n",
    "print(f\"验证集大小: {len(val_loader.dataset)}\")\n",
    "print(f\"测试集大小: {len(test_loader.dataset)}\")\n",
    "\n",
    "# 获取类别数量\n",
    "label_num = len(full_dataset.class_to_idx)\n",
    "\n",
    "# 数据可视化\n",
    "to_img = T.ToPILImage()\n",
    "a = to_img(train_loader.dataset[0][0])  # size=[1, 32, 32]\n",
    "plt.imshow(a)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "a81c0144afddb0a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集每个类别样本数：\n",
      "类别 0: 700\n",
      "类别 1: 700\n",
      "类别 2: 700\n",
      "类别 3: 700\n",
      "类别 4: 700\n",
      "类别 5: 700\n",
      "类别 6: 700\n",
      "类别 7: 700\n",
      "类别 8: 700\n",
      "类别 9: 700\n",
      "类别 A: 700\n",
      "类别 B: 700\n",
      "类别 C: 700\n",
      "类别 D: 700\n",
      "类别 E: 700\n",
      "类别 F: 700\n",
      "类别 G: 700\n",
      "类别 H: 700\n",
      "类别 I: 700\n",
      "类别 J: 700\n",
      "类别 K: 700\n",
      "类别 L: 700\n",
      "类别 M: 700\n",
      "类别 N: 700\n",
      "类别 O: 700\n",
      "类别 P: 700\n",
      "类别 Q: 700\n",
      "类别 R: 700\n",
      "类别 S: 700\n",
      "类别 T: 700\n",
      "类别 U: 700\n",
      "类别 V: 700\n",
      "类别 W: 700\n",
      "类别 X: 700\n",
      "类别 Y: 700\n",
      "类别 Z: 700\n",
      "类别 a_: 700\n",
      "类别 b_: 700\n",
      "类别 d_: 700\n",
      "类别 e_: 700\n",
      "类别 f_: 700\n",
      "类别 g_: 700\n",
      "类别 h_: 700\n",
      "类别 n_: 700\n",
      "类别 q_: 700\n",
      "类别 r_: 700\n",
      "类别 t_: 700\n",
      "\n",
      "验证集每个类别样本数：\n",
      "类别 0: 150\n",
      "类别 1: 150\n",
      "类别 2: 150\n",
      "类别 3: 150\n",
      "类别 4: 150\n",
      "类别 5: 150\n",
      "类别 6: 150\n",
      "类别 7: 150\n",
      "类别 8: 150\n",
      "类别 9: 150\n",
      "类别 A: 150\n",
      "类别 B: 150\n",
      "类别 C: 150\n",
      "类别 D: 150\n",
      "类别 E: 150\n",
      "类别 F: 150\n",
      "类别 G: 150\n",
      "类别 H: 150\n",
      "类别 I: 150\n",
      "类别 J: 150\n",
      "类别 K: 150\n",
      "类别 L: 150\n",
      "类别 M: 150\n",
      "类别 N: 150\n",
      "类别 O: 150\n",
      "类别 P: 150\n",
      "类别 Q: 150\n",
      "类别 R: 150\n",
      "类别 S: 150\n",
      "类别 T: 150\n",
      "类别 U: 150\n",
      "类别 V: 150\n",
      "类别 W: 150\n",
      "类别 X: 150\n",
      "类别 Y: 150\n",
      "类别 Z: 150\n",
      "类别 a_: 150\n",
      "类别 b_: 150\n",
      "类别 d_: 150\n",
      "类别 e_: 150\n",
      "类别 f_: 150\n",
      "类别 g_: 150\n",
      "类别 h_: 150\n",
      "类别 n_: 150\n",
      "类别 q_: 150\n",
      "类别 r_: 150\n",
      "类别 t_: 150\n",
      "\n",
      "测试集每个类别样本数：\n",
      "类别 0: 150\n",
      "类别 1: 150\n",
      "类别 2: 150\n",
      "类别 3: 150\n",
      "类别 4: 150\n",
      "类别 5: 150\n",
      "类别 6: 150\n",
      "类别 7: 150\n",
      "类别 8: 150\n",
      "类别 9: 150\n",
      "类别 A: 150\n",
      "类别 B: 150\n",
      "类别 C: 150\n",
      "类别 D: 150\n",
      "类别 E: 150\n",
      "类别 F: 150\n",
      "类别 G: 150\n",
      "类别 H: 150\n",
      "类别 I: 150\n",
      "类别 J: 150\n",
      "类别 K: 150\n",
      "类别 L: 150\n",
      "类别 M: 150\n",
      "类别 N: 150\n",
      "类别 O: 150\n",
      "类别 P: 150\n",
      "类别 Q: 150\n",
      "类别 R: 150\n",
      "类别 S: 150\n",
      "类别 T: 150\n",
      "类别 U: 150\n",
      "类别 V: 150\n",
      "类别 W: 150\n",
      "类别 X: 150\n",
      "类别 Y: 150\n",
      "类别 Z: 150\n",
      "类别 a_: 150\n",
      "类别 b_: 150\n",
      "类别 d_: 150\n",
      "类别 e_: 150\n",
      "类别 f_: 150\n",
      "类别 g_: 150\n",
      "类别 h_: 150\n",
      "类别 n_: 150\n",
      "类别 q_: 150\n",
      "类别 r_: 150\n",
      "类别 t_: 150\n",
      "训练集大小: 32900\n",
      "验证集大小: 7050\n",
      "测试集大小: 7050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 训练模型（有注意力机制）",
   "id": "ccb787c7a53d124a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T13:50:59.097070Z",
     "start_time": "2025-04-22T13:50:06.288583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = CNNWithAttention(label_num, use_attention=True) # 调用模型\n",
    "print(model)\n",
    "\n",
    "train_and_validate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCH,\n",
    "    device=device,\n",
    "    save_path=\"cnn_res_attention_aug_best.pth\",\n",
    ")\n",
    "\n",
    "print(\"训练结束。\")"
   ],
   "id": "b0986ea8c8f86262",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNWithAttention(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (residual): ResidualBlock(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (attn): SimpleAttention(\n",
      "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "        (3): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential()\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (inverted_residual): InvertedResidualBlock(\n",
      "    (block): Sequential(\n",
      "      (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "      (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "      (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU6(inplace=True)\n",
      "      (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (attn): SimpleAttention(\n",
      "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "        (3): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (attention): SelfAttention2D(\n",
      "    (query): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (key): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (value): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (fcon1): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=1)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=148, bias=True)\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (fcon2): Linear(in_features=148, out_features=47, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m model = CNNWithAttention(label_num, use_attention=\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;66;03m# 调用模型\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(model)\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[43mtrain_and_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mEPOCH\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave_path\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcnn_res_attention_aug_best.pth\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m训练结束。\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\Com_Intelligent_work\\myCnn\\cnnWithAttention\\train_my_cnn.py:46\u001B[39m, in \u001B[36mtrain_and_validate\u001B[39m\u001B[34m(model, train_loader, val_loader, epochs, device, save_path, save_best_only, patience, auto_lr, lr, LOG_DIR)\u001B[39m\n\u001B[32m     43\u001B[39m loss = loss_func(outputs, batch_y)\n\u001B[32m     45\u001B[39m optimizer.zero_grad()\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     47\u001B[39m optimizer.step()\n\u001B[32m     49\u001B[39m total_loss += loss.item() * batch_x.size(\u001B[32m0\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\Com_Intelligent_work\\venv\\Lib\\site-packages\\torch\\_tensor.py:626\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    616\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    617\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    618\u001B[39m         Tensor.backward,\n\u001B[32m    619\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    624\u001B[39m         inputs=inputs,\n\u001B[32m    625\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m626\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    627\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    628\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\Com_Intelligent_work\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    342\u001B[39m     retain_graph = create_graph\n\u001B[32m    344\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    345\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    346\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m347\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    348\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    349\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    350\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    351\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    352\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    353\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\Com_Intelligent_work\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    821\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    822\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m823\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    824\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    825\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    826\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    827\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 训练模型（无注意力机制）",
   "id": "ffa9536746cc0b39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = CNNWithAttention(label_num, use_attention=False) # 调用模型\n",
    "\n",
    "train_and_validate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCH,\n",
    "    device=device,\n",
    "    save_path=\"cnn_res_noattention_aug_best.pth\"\n",
    ")"
   ],
   "id": "abb212bc14be649c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 无数据增强",
   "id": "a08cd8dc8310aac9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "transform = AlbumentationsTransformBase()  # 不使用数据增强\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader, full_dataset = split_dataset(\n",
    "    root_dir=ROOT_DIR,\n",
    "    transform=transform,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "# 打印数据集大小\n",
    "print(f\"训练集大小: {len(train_loader.dataset)}\")\n",
    "print(f\"验证集大小: {len(val_loader.dataset)}\")\n",
    "print(f\"测试集大小: {len(test_loader.dataset)}\")\n",
    "\n",
    "# 获取类别数量\n",
    "label_num = len(full_dataset.class_to_idx)\n",
    "\n",
    "# 数据可视化\n",
    "to_img = T.ToPILImage()\n",
    "a = to_img(train_loader.dataset[0][0])  # size=[1, 32, 32]\n",
    "plt.imshow(a)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "884b710e5601641c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 训练模型（有注意力机制）",
   "id": "570e9cd41429298f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = CNNWithAttention(label_num, use_attention=True) # 调用模型\n",
    "\n",
    "train_and_validate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCH,\n",
    "    device=device,\n",
    "    save_path=\"cnn_res_attention_noaug_best.pth\",\n",
    "    lr=LR\n",
    ")"
   ],
   "id": "51e75e8955bf5ee6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 训练模型（无注意力机制）",
   "id": "6f3ddb4d7a41a227"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = CNNWithAttention(label_num, use_attention=False) # 调用模型\n",
    "\n",
    "train_and_validate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCH,\n",
    "    device=device,\n",
    "    save_path=\"cnn_res_noattention_noaug_best.pth\",\n",
    "    lr=LR\n",
    ")"
   ],
   "id": "90651f1fb456153a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
