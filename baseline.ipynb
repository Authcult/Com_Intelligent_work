{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 基于卷积神经网络的手写英文字母识别系统研究",
   "id": "29d8411876dc3158"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 准备数据集及数据预处理",
   "id": "d78e90008e2c5af2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 将下载的数据集按类重命名",
   "id": "42bdf484f2841253"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T10:58:51.448962Z",
     "start_time": "2025-04-18T10:58:51.445825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# import os\n",
    "# import string\n",
    "#\n",
    "# # 定义源目录路径\n",
    "# source_dir = \"EnglishHnd/EnglishHnd/English/Hnd/Img\"\n",
    "#\n",
    "# # 生成目标文件夹名称列表\n",
    "# target_folders = list(string.digits) + list(string.ascii_uppercase) + [f\"{char}_\" for char in string.ascii_lowercase]\n",
    "#\n",
    "# # 获取源目录下的所有文件夹名称\n",
    "# source_folders = sorted([f for f in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, f))])\n",
    "#\n",
    "# # 确保源文件夹数量与目标文件夹数量一致\n",
    "# if len(source_folders) != len(target_folders):\n",
    "#     raise ValueError(\"源文件夹数量与目标文件夹数量不一致\")\n",
    "#\n",
    "# # 重命名文件夹\n",
    "# for source_folder, target_folder in zip(source_folders, target_folders):\n",
    "#     source_path = os.path.join(source_dir, source_folder)\n",
    "#     target_path = os.path.join(source_dir, target_folder)\n",
    "#\n",
    "#     try:\n",
    "#         os.rename(source_path, target_path)\n",
    "#         print(f\"重命名: {source_path} -> {target_path}\")\n",
    "#     except FileExistsError:\n",
    "#         print(f\"目标文件夹 {target_path} 已存在，跳过重命名 {source_path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"重命名 {source_path} 到 {target_path} 时出错: {e}\")\n",
    "\n",
    "\n"
   ],
   "id": "54deffa73ea10393",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 划分训练集和测试集",
   "id": "5fcdbfa1cc4582f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T10:58:57.305733Z",
     "start_time": "2025-04-18T10:58:51.470964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "#数据增强\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from myCnn.baseline.LeNet5 import LeNet5\n",
    "from myCnn.train_model import train_model\n",
    "from myCnn.utils import split_dataset\n",
    "from myCnn.baseline.resnet18 import resnet18\n",
    "from myCnn.baseline.mobilenet_v2 import mobilenet_v2\n",
    "from myCnn.baseline.svm_model import train_svm, flatten_images\n",
    "from myCnn.CBAMNet_Lite import CharsLightAttentionNet\n",
    "from myCnn.evaluate_model import evaluate_model\n",
    "EPOCH = 100\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-4"
   ],
   "id": "aacf2af0e69ea029",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T10:58:57.373562Z",
     "start_time": "2025-04-18T10:58:57.368049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # 定义数据预处理变换\n",
    "# transform = T.Compose([\n",
    "#     T.Resize((64, 64)),\n",
    "#     T.Grayscale(num_output_channels=3),\n",
    "#     T.RandomRotation(15),  # 数据增强：随机旋转\n",
    "#     T.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 位移\n",
    "#     T.ToTensor(),\n",
    "#     # 如果需要标准化，可以取消注释以下行\n",
    "#     T.Normalize([0.5], [0.5])\n",
    "# ])\n",
    "class AlbumentationsTransform:\n",
    "    def __init__(self):\n",
    "        self.transform=A.Compose([\n",
    "            A.Resize(32, 32),\n",
    "            A.Rotate(limit=15, p=0.5),\n",
    "            A.Affine(translate_percent=(0.1,0.1),p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.3),\n",
    "            A.Normalize(mean=(0.5,),std=(0.5,)),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    def __call__(self, img):\n",
    "        img=np.array(img)\n",
    "        # img = np.array(img.convert('L'))\n",
    "        return self.transform(image=img)['image']\n",
    "\n",
    "transform=AlbumentationsTransform()\n"
   ],
   "id": "b16d345b5d36a44b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T10:58:57.445058Z",
     "start_time": "2025-04-18T10:58:57.379201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用函数划分数据集\n",
    "train_loader, val_loader, test_loader, full_dataset = split_dataset(\n",
    "    root_dir=\"EnglishHnd/EnglishHnd/English/Hnd/Img\",\n",
    "    # root_dir=\"EnglishImg/EnglishImg/English/Img/GoodImg/Bmp\",\n",
    "    transform=transform,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# 打印数据集大小\n",
    "print(f\"训练集大小: {len(train_loader.dataset)}\")\n",
    "print(f\"验证集大小: {len(val_loader.dataset)}\")\n",
    "print(f\"测试集大小: {len(test_loader.dataset)}\")\n",
    "\n",
    "# 获取类别数量\n",
    "label_num = len(full_dataset.class_to_idx)\n",
    "print(full_dataset.class_to_idx)\n",
    "# 数据可视化\n",
    "to_img = T.ToPILImage()\n",
    "a = to_img(train_loader.dataset[0][0])  # size=[1, 28, 28]\n",
    "plt.imshow(a)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 获取类别数量\n",
    "label_num = len(full_dataset.class_to_idx)"
   ],
   "id": "534ac135f4b7c37d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 2387\n",
      "验证集大小: 511\n",
      "测试集大小: 512\n",
      "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'A': 10, 'B': 11, 'C': 12, 'D': 13, 'E': 14, 'F': 15, 'G': 16, 'H': 17, 'I': 18, 'J': 19, 'K': 20, 'L': 21, 'M': 22, 'N': 23, 'O': 24, 'P': 25, 'Q': 26, 'R': 27, 'S': 28, 'T': 29, 'U': 30, 'V': 31, 'W': 32, 'X': 33, 'Y': 34, 'Z': 35, 'a_': 36, 'b_': 37, 'c_': 38, 'd_': 39, 'e_': 40, 'f_': 41, 'g_': 42, 'h_': 43, 'i_': 44, 'j_': 45, 'k_': 46, 'l_': 47, 'm_': 48, 'n_': 49, 'o_': 50, 'p_': 51, 'q_': 52, 'r_': 53, 's_': 54, 't_': 55, 'u_': 56, 'v_': 57, 'w_': 58, 'x_': 59, 'y_': 60, 'z_': 61}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T10:58:57.453411Z",
     "start_time": "2025-04-18T10:58:57.451540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# # 获取展平后的训练集和验证集\n",
    "# X_train, y_train = flatten_images(train_loader)\n",
    "# X_val, y_val = flatten_images(val_loader)"
   ],
   "id": "9974f896064aacd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T10:58:57.481868Z",
     "start_time": "2025-04-18T10:58:57.478887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# # 训练SVM模型\n",
    "# svm_clf, train_acc, val_acc = train_svm(X_train, y_train, X_val, y_val)"
   ],
   "id": "87aa03faed3bbc5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T10:58:57.647937Z",
     "start_time": "2025-04-18T10:58:57.500402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 初始化模型\n",
    "cnn = mobilenet_v2(pretrained=True)\n",
    "# 加载最好的权重模型\n",
    "# cnn.load_state_dict(torch.load('myCnn/baseline_weight/resnet18_best_model.pth'))\n",
    "\n",
    "print(cnn)\n",
    "\n",
    "# 检查 CUDA 是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn.to(device)  # 将模型迁移到 GPU\n",
    "\n",
    "# 假设使用cpu\n",
    "# cnn.to('cpu')\n",
    "\n",
    "# 创建优化器\n",
    "optimizer = torch.optim.AdamW(cnn.parameters(), lr=3e-4, weight_decay=0.05)\n",
    "\n",
    "# 创建学习率调度器（Cosine退火）\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=EPOCH,  # 周期长度\n",
    "    eta_min=1e-5       # 最小学习率\n",
    ")\n",
    "\n",
    "# 定义损失函数\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "id": "933478ec4153ccbc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\app\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\app\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T10:59:00.123689Z",
     "start_time": "2025-04-18T10:58:57.658938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练模型\n",
    "cnn = train_model(cnn, train_loader, val_loader, loss_func, optimizer, num_epochs=EPOCH)\n",
    "\n"
   ],
   "id": "537b5b45180d29b0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 18:58:57,659 - INFO - Using device: cuda\n",
      "2025-04-18 18:58:57,664 - INFO - Starting training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 训练模型\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m cnn \u001B[38;5;241m=\u001B[39m train_model(cnn, train_loader, val_loader, loss_func, optimizer, num_epochs\u001B[38;5;241m=\u001B[39mEPOCH)\n",
      "File \u001B[1;32mE:\\计算智能\\myCnn\\train_model.py:34\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, save_path, save_best_only)\u001B[0m\n\u001B[0;32m     31\u001B[0m top3_correct_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     32\u001B[0m total_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 34\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (images, labels) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[0;32m     35\u001B[0m     images, labels \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     37\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model(images)\n",
      "File \u001B[1;32mD:\\app\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    707\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 708\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[0;32m    709\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    710\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    711\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    712\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    713\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    714\u001B[0m ):\n",
      "File \u001B[1;32mD:\\app\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    762\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    763\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 764\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    765\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    766\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mD:\\app\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__getitems__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__:\n\u001B[1;32m---> 50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "File \u001B[1;32mD:\\app\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001B[0m, in \u001B[0;36mSubset.__getitems__\u001B[1;34m(self, indices)\u001B[0m\n\u001B[0;32m    418\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    419\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 420\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx]] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[1;32mD:\\app\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:247\u001B[0m, in \u001B[0;36mDatasetFolder.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    245\u001B[0m sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader(path)\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 247\u001B[0m     sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(sample)\n\u001B[0;32m    248\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    249\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform(target)\n",
      "Cell \u001B[1;32mIn[3], line 22\u001B[0m, in \u001B[0;36mAlbumentationsTransform.__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[1;32m---> 22\u001B[0m     img\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39marray(img)\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;66;03m# img = np.array(img.convert('L'))\u001B[39;00m\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(image\u001B[38;5;241m=\u001B[39mimg)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32mD:\\app\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:696\u001B[0m, in \u001B[0;36mImage.__array_interface__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    694\u001B[0m         new[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtobytes(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mL\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    695\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 696\u001B[0m         new[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[0;32m    697\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    698\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, (\u001B[38;5;167;01mMemoryError\u001B[39;00m, \u001B[38;5;167;01mRecursionError\u001B[39;00m)):\n",
      "File \u001B[1;32mD:\\app\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:776\u001B[0m, in \u001B[0;36mImage.tobytes\u001B[1;34m(self, encoder_name, *args)\u001B[0m\n\u001B[0;32m    773\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder error \u001B[39m\u001B[38;5;132;01m{\u001B[39;00merrcode\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m in tobytes\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    774\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg)\n\u001B[1;32m--> 776\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(output)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T10:59:00.132330500Z",
     "start_time": "2025-04-18T09:55:39.429687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 推理\n",
    "\n",
    "top1_acc, top3_acc, inference_speed = evaluate_model(cnn, test_loader, device)\n",
    "print(f\"Top-1 Accuracy: {top1_acc:.4f}\")\n",
    "print(f\"Top-3 Accuracy: {top3_acc:.4f}\")\n",
    "print(f\"Inference Speed: {inference_speed * 1000:.4f} ms per sample\")"
   ],
   "id": "44445d68673d35ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 72.2656\n",
      "Top-3 Accuracy: 92.1875\n",
      "Inference Speed: 0.0234 ms per sample\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
