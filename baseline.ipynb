{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 基于卷积神经网络的手写英文字母识别系统研究",
   "id": "29d8411876dc3158"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 准备数据集及数据预处理",
   "id": "d78e90008e2c5af2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 将下载的数据集按类重命名",
   "id": "42bdf484f2841253"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# import os\n",
    "# import string\n",
    "#\n",
    "# # 定义源目录路径\n",
    "# source_dir = \"EnglishHnd/EnglishHnd/English/Hnd/Img\"\n",
    "#\n",
    "# # 生成目标文件夹名称列表\n",
    "# target_folders = list(string.digits) + list(string.ascii_uppercase) + [f\"{char}_\" for char in string.ascii_lowercase]\n",
    "#\n",
    "# # 获取源目录下的所有文件夹名称\n",
    "# source_folders = sorted([f for f in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, f))])\n",
    "#\n",
    "# # 确保源文件夹数量与目标文件夹数量一致\n",
    "# if len(source_folders) != len(target_folders):\n",
    "#     raise ValueError(\"源文件夹数量与目标文件夹数量不一致\")\n",
    "#\n",
    "# # 重命名文件夹\n",
    "# for source_folder, target_folder in zip(source_folders, target_folders):\n",
    "#     source_path = os.path.join(source_dir, source_folder)\n",
    "#     target_path = os.path.join(source_dir, target_folder)\n",
    "#\n",
    "#     try:\n",
    "#         os.rename(source_path, target_path)\n",
    "#         print(f\"重命名: {source_path} -> {target_path}\")\n",
    "#     except FileExistsError:\n",
    "#         print(f\"目标文件夹 {target_path} 已存在，跳过重命名 {source_path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"重命名 {source_path} 到 {target_path} 时出错: {e}\")\n",
    "\n",
    "\n"
   ],
   "id": "54deffa73ea10393"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 划分训练集和测试集",
   "id": "5fcdbfa1cc4582f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "#数据增强\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from myCnn.baseline.LeNet5 import LeNet5\n",
    "from myCnn.train_model import train_model\n",
    "from myCnn.utils import split_dataset\n",
    "from myCnn.baseline.resnet18 import resnet18\n",
    "from myCnn.baseline.mobilenet_v2 import mobilenet_v2\n",
    "from myCnn.baseline.svm_model import train_svm, flatten_images\n",
    "from myCnn.CBAMNet_Lite import CharsLightAttentionNet\n",
    "from myCnn.evaluate_model import evaluate_model\n",
    "EPOCH = 100\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-4"
   ],
   "id": "aacf2af0e69ea029"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # 定义数据预处理变换\n",
    "# transform = T.Compose([\n",
    "#     T.Resize((64, 64)),\n",
    "#     T.Grayscale(num_output_channels=3),\n",
    "#     T.RandomRotation(15),  # 数据增强：随机旋转\n",
    "#     T.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 位移\n",
    "#     T.ToTensor(),\n",
    "#     # 如果需要标准化，可以取消注释以下行\n",
    "#     T.Normalize([0.5], [0.5])\n",
    "# ])\n",
    "class AlbumentationsTransform:\n",
    "    def __init__(self):\n",
    "        self.transform=A.Compose([\n",
    "            A.Resize(32, 32),\n",
    "            A.Rotate(limit=15, p=0.5),\n",
    "            A.Affine(translate_percent=(0.1,0.1),p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.3),\n",
    "            A.Normalize(mean=(0.5,),std=(0.5,)),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    def __call__(self, img):\n",
    "        img=np.array(img)\n",
    "        return self.transform(image=img)['image']\n",
    "\n",
    "transform=AlbumentationsTransform()\n"
   ],
   "id": "b16d345b5d36a44b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 使用函数划分数据集\n",
    "train_loader, val_loader, test_loader, full_dataset = split_dataset(\n",
    "    root_dir=\"EnglishHnd/EnglishHnd/English/Hnd/Img\",\n",
    "    # root_dir=\"EnglishImg/EnglishImg/English/Img/GoodImg/Bmp\",\n",
    "    transform=transform,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# 打印数据集大小\n",
    "print(f\"训练集大小: {len(train_loader.dataset)}\")\n",
    "print(f\"验证集大小: {len(val_loader.dataset)}\")\n",
    "print(f\"测试集大小: {len(test_loader.dataset)}\")\n",
    "\n",
    "# 获取类别数量\n",
    "label_num = len(full_dataset.class_to_idx)\n",
    "\n",
    "# 数据可视化\n",
    "to_img = T.ToPILImage()\n",
    "a = to_img(train_loader.dataset[0][0])  # size=[1, 28, 28]\n",
    "plt.imshow(a)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 获取类别数量\n",
    "label_num = len(full_dataset.class_to_idx)"
   ],
   "id": "534ac135f4b7c37d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# # 获取展平后的训练集和验证集\n",
    "# X_train, y_train = flatten_images(train_loader)\n",
    "# X_val, y_val = flatten_images(val_loader)"
   ],
   "id": "9974f896064aacd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# # 训练SVM模型\n",
    "# svm_clf, train_acc, val_acc = train_svm(X_train, y_train, X_val, y_val)"
   ],
   "id": "87aa03faed3bbc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# 初始化模型\n",
    "cnn = CharsLightAttentionNet(num_classes=label_num)\n",
    "# 加载最好的模型\n",
    "cnn.load_state_dict(torch.load('myCnn/v1/best_model.pth'))\n",
    "\n",
    "print(cnn)\n",
    "\n",
    "# 检查 CUDA 是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn.to(device)  # 将模型迁移到 GPU\n",
    "\n",
    "# 创建优化器\n",
    "optimizer = torch.optim.AdamW(cnn.parameters(), lr=3e-4, weight_decay=0.05)\n",
    "\n",
    "# 创建学习率调度器（Cosine退火）\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=EPOCH,  # 周期长度\n",
    "    eta_min=1e-5       # 最小学习率\n",
    ")\n",
    "\n",
    "# 定义损失函数\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "id": "933478ec4153ccbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 训练模型\n",
    "# cnn = train_model(cnn, train_loader, val_loader, loss_func, optimizer, scheduler=scheduler,num_epochs=EPOCH)\n",
    "\n"
   ],
   "id": "537b5b45180d29b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 推理\n",
    "\n",
    "top1_acc, top3_acc, inference_speed = evaluate_model(cnn, test_loader, device)\n",
    "print(f\"Top-1 Accuracy: {top1_acc:.4f}\")\n",
    "print(f\"Top-3 Accuracy: {top3_acc:.4f}\")\n",
    "print(f\"Inference Speed: {inference_speed * 1000:.4f} ms per sample\")"
   ],
   "id": "44445d68673d35ef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
