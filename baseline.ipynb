{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 基于卷积神经网络的手写英文字母识别系统研究",
   "id": "29d8411876dc3158"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 准备数据集及数据预处理",
   "id": "d78e90008e2c5af2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 将下载的数据集按类重命名",
   "id": "42bdf484f2841253"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T05:58:54.024788Z",
     "start_time": "2025-04-20T05:58:54.020682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# import os\n",
    "# import string\n",
    "#\n",
    "# # 定义源目录路径\n",
    "# source_dir = \"EnglishHnd/EnglishHnd/English/Hnd/Img\"\n",
    "#\n",
    "# # 生成目标文件夹名称列表\n",
    "# target_folders = list(string.digits) + list(string.ascii_uppercase) + [f\"{char}_\" for char in string.ascii_lowercase]\n",
    "#\n",
    "# # 获取源目录下的所有文件夹名称\n",
    "# source_folders = sorted([f for f in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, f))])\n",
    "#\n",
    "# # 确保源文件夹数量与目标文件夹数量一致\n",
    "# if len(source_folders) != len(target_folders):\n",
    "#     raise ValueError(\"源文件夹数量与目标文件夹数量不一致\")\n",
    "#\n",
    "# # 重命名文件夹\n",
    "# for source_folder, target_folder in zip(source_folders, target_folders):\n",
    "#     source_path = os.path.join(source_dir, source_folder)\n",
    "#     target_path = os.path.join(source_dir, target_folder)\n",
    "#\n",
    "#     try:\n",
    "#         os.rename(source_path, target_path)\n",
    "#         print(f\"重命名: {source_path} -> {target_path}\")\n",
    "#     except FileExistsError:\n",
    "#         print(f\"目标文件夹 {target_path} 已存在，跳过重命名 {source_path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"重命名 {source_path} 到 {target_path} 时出错: {e}\")\n"
   ],
   "id": "54deffa73ea10393",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 划分训练集和测试集",
   "id": "5fcdbfa1cc4582f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T05:59:04.537161Z",
     "start_time": "2025-04-20T05:58:54.028871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "#数据增强\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from myCnn.baseline.LeNet5 import LeNet5\n",
    "from myCnn.train_model import train_model\n",
    "from myCnn.utils import split_dataset\n",
    "from myCnn.baseline.resnet18 import resnet18\n",
    "from myCnn.baseline.mobilenet_v2 import mobilenet_v2\n",
    "from myCnn.baseline.svm_model import train_svm, flatten_images\n",
    "from myCnn.CBAMNet_Lite import CharsLightAttentionNet\n",
    "from myCnn.evaluate_model import evaluate_model\n",
    "from myCnn.MobileNetV2_SE import MobileNetV2_SE\n",
    "EPOCH = 100\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-4"
   ],
   "id": "aacf2af0e69ea029",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T05:59:04.604886Z",
     "start_time": "2025-04-20T05:59:04.598171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # 定义数据预处理变换\n",
    "# transform = T.Compose([\n",
    "#     T.Resize((64, 64)),\n",
    "#     T.Grayscale(num_output_channels=3),\n",
    "#     T.RandomRotation(15),  # 数据增强：随机旋转\n",
    "#     T.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 位移\n",
    "#     T.ToTensor(),\n",
    "#     # 如果需要标准化，可以取消注释以下行\n",
    "#     T.Normalize([0.5], [0.5])\n",
    "# ])\n",
    "class AlbumentationsTransform:\n",
    "    def __init__(self):\n",
    "        self.transform=A.Compose([\n",
    "            A.Resize(28, 28),\n",
    "            A.Rotate(limit=15, p=0.5),\n",
    "            A.Affine(translate_percent=(0.1,0.1),p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.3),\n",
    "            A.Normalize(mean=(0.5,),std=(0.5,)),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    def __call__(self, img):\n",
    "        img=np.array(img)\n",
    "        # img = np.array(img.convert('L'))\n",
    "        return self.transform(image=img)['image']\n",
    "\n",
    "transform=AlbumentationsTransform()\n"
   ],
   "id": "b16d345b5d36a44b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T05:59:04.735102Z",
     "start_time": "2025-04-20T05:59:04.610916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用函数划分数据集\n",
    "train_loader, val_loader, test_loader, full_dataset = split_dataset(\n",
    "    root_dir=\"emnist_png_balanced\",\n",
    "    # root_dir=\"EnglishImg/EnglishImg/English/Img/GoodImg/Bmp\",\n",
    "    transform=transform,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# 打印数据集大小\n",
    "print(f\"训练集大小: {len(train_loader.dataset)}\")\n",
    "print(f\"验证集大小: {len(val_loader.dataset)}\")\n",
    "print(f\"测试集大小: {len(test_loader.dataset)}\")\n",
    "\n",
    "# 获取类别数量\n",
    "label_num = len(full_dataset.class_to_idx)\n",
    "print(full_dataset.class_to_idx)\n",
    "# 数据可视化\n",
    "to_img = T.ToPILImage()\n",
    "a = to_img(train_loader.dataset[0][0])  # size=[1, 28, 28]\n",
    "plt.imshow(a)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 获取类别数量\n",
    "label_num = len(full_dataset.class_to_idx)"
   ],
   "id": "534ac135f4b7c37d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 32900\n",
      "验证集大小: 7050\n",
      "测试集大小: 7050\n",
      "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'A': 10, 'B': 11, 'C': 12, 'D': 13, 'E': 14, 'F': 15, 'G': 16, 'H': 17, 'I': 18, 'J': 19, 'K': 20, 'L': 21, 'M': 22, 'N': 23, 'O': 24, 'P': 25, 'Q': 26, 'R': 27, 'S': 28, 'T': 29, 'U': 30, 'V': 31, 'W': 32, 'X': 33, 'Y': 34, 'Z': 35, 'a_': 36, 'b_': 37, 'd_': 38, 'e_': 39, 'f_': 40, 'g_': 41, 'h_': 42, 'n_': 43, 'q_': 44, 'r_': 45, 't_': 46}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T05:59:04.743566Z",
     "start_time": "2025-04-20T05:59:04.741242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# # 获取展平后的训练集和验证集\n",
    "# X_train, y_train = flatten_images(train_loader)\n",
    "# X_val, y_val = flatten_images(val_loader)"
   ],
   "id": "9974f896064aacd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T05:59:04.758906Z",
     "start_time": "2025-04-20T05:59:04.757025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# # 训练SVM模型\n",
    "# svm_clf, train_acc, val_acc = train_svm(X_train, y_train, X_val, y_val)"
   ],
   "id": "87aa03faed3bbc5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T07:12:28.233323Z",
     "start_time": "2025-04-20T07:12:28.191428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 初始化模型\n",
    "cnn = MobileNetV2_SE(num_classes=label_num)\n",
    "# 加载最好的权重模型\n",
    "# cnn.load_state_dict(torch.load('myCnn/best_model.pth'))\n",
    "\n",
    "print(cnn)\n",
    "\n",
    "# 检查 CUDA 是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn.to(device)  # 将模型迁移到 GPU\n",
    "\n",
    "# 假设使用cpu\n",
    "# cnn.to('cpu')\n",
    "\n",
    "# 创建优化器\n",
    "optimizer = torch.optim.AdamW(cnn.parameters(), lr=3e-4, weight_decay=0.05)\n",
    "\n",
    "# 创建学习率调度器（Cosine退火）\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=EPOCH,  # 周期长度\n",
    "    eta_min=1e-5       # 最小学习率\n",
    ")\n",
    "\n",
    "# 定义损失函数\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "id": "933478ec4153ccbc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2_SE(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6()\n",
      "    (3): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (4): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (19): InvertedResidualSE(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): SEBlock(\n",
      "          (se): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (20): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (21): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU6()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=1)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=1280, out_features=47, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T07:47:13.320110Z",
     "start_time": "2025-04-20T07:12:30.383168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练模型\n",
    "cnn = train_model(cnn, train_loader, val_loader, loss_func, optimizer, scheduler=scheduler,num_epochs=EPOCH)\n",
    "\n"
   ],
   "id": "537b5b45180d29b0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 15:12:30,385 - INFO - Using device: cuda\n",
      "2025-04-20 15:12:30,390 - INFO - Starting training...\n",
      "2025-04-20 15:12:51,949 - INFO - Epoch [1/100], Train Loss: 3.2953, Train Top-1: 12.88%, Train Top-3: 28.64%, | Val Loss: 2.4537, Val Top-1: 28.74%, Val Top-3: 56.62%\n",
      "2025-04-20 15:13:13,499 - INFO - Epoch [2/100], Train Loss: 1.8792, Train Top-1: 42.92%, Train Top-3: 71.64%, | Val Loss: 1.4471, Val Top-1: 54.62%, Val Top-3: 82.64%\n",
      "2025-04-20 15:13:35,857 - INFO - Epoch [3/100], Train Loss: 1.2591, Train Top-1: 59.42%, Train Top-3: 86.02%, | Val Loss: 1.1093, Val Top-1: 64.65%, Val Top-3: 89.45%\n",
      "2025-04-20 15:13:56,356 - INFO - Epoch [4/100], Train Loss: 0.9819, Train Top-1: 68.02%, Train Top-3: 91.05%, | Val Loss: 0.9288, Val Top-1: 69.50%, Val Top-3: 91.80%\n",
      "2025-04-20 15:14:17,269 - INFO - Epoch [5/100], Train Loss: 0.8561, Train Top-1: 71.82%, Train Top-3: 92.92%, | Val Loss: 0.8077, Val Top-1: 73.67%, Val Top-3: 93.25%\n",
      "2025-04-20 15:14:37,630 - INFO - Epoch [6/100], Train Loss: 0.7834, Train Top-1: 73.61%, Train Top-3: 94.18%, | Val Loss: 0.7371, Val Top-1: 75.86%, Val Top-3: 94.57%\n",
      "2025-04-20 15:14:58,245 - INFO - Epoch [7/100], Train Loss: 0.6792, Train Top-1: 76.92%, Train Top-3: 95.44%, | Val Loss: 0.6947, Val Top-1: 77.15%, Val Top-3: 95.28%\n",
      "2025-04-20 15:15:18,443 - INFO - Epoch [8/100], Train Loss: 0.6330, Train Top-1: 78.30%, Train Top-3: 95.94%, | Val Loss: 0.6696, Val Top-1: 77.74%, Val Top-3: 95.08%\n",
      "2025-04-20 15:15:39,281 - INFO - Epoch [9/100], Train Loss: 0.6069, Train Top-1: 78.99%, Train Top-3: 96.36%, | Val Loss: 0.6240, Val Top-1: 79.05%, Val Top-3: 95.93%\n",
      "2025-04-20 15:15:59,474 - INFO - Epoch [10/100], Train Loss: 0.5586, Train Top-1: 80.51%, Train Top-3: 96.85%, | Val Loss: 0.6012, Val Top-1: 79.42%, Val Top-3: 96.27%\n",
      "2025-04-20 15:16:19,757 - INFO - Epoch [11/100], Train Loss: 0.5504, Train Top-1: 80.83%, Train Top-3: 96.98%, | Val Loss: 0.5884, Val Top-1: 80.17%, Val Top-3: 96.43%\n",
      "2025-04-20 15:16:43,483 - INFO - Epoch [12/100], Train Loss: 0.5195, Train Top-1: 81.87%, Train Top-3: 97.29%, | Val Loss: 0.5899, Val Top-1: 80.17%, Val Top-3: 96.16%\n",
      "2025-04-20 15:17:09,307 - INFO - Epoch [13/100], Train Loss: 0.5304, Train Top-1: 81.62%, Train Top-3: 97.15%, | Val Loss: 0.5552, Val Top-1: 80.89%, Val Top-3: 96.55%\n",
      "2025-04-20 15:17:35,067 - INFO - Epoch [14/100], Train Loss: 0.4897, Train Top-1: 82.64%, Train Top-3: 97.64%, | Val Loss: 0.5379, Val Top-1: 81.55%, Val Top-3: 96.94%\n",
      "2025-04-20 15:17:58,025 - INFO - Epoch [15/100], Train Loss: 0.4648, Train Top-1: 83.44%, Train Top-3: 97.86%, | Val Loss: 0.5198, Val Top-1: 82.26%, Val Top-3: 97.18%\n",
      "2025-04-20 15:18:18,393 - INFO - Epoch [16/100], Train Loss: 0.4465, Train Top-1: 84.08%, Train Top-3: 97.90%, | Val Loss: 0.5036, Val Top-1: 83.15%, Val Top-3: 97.42%\n",
      "2025-04-20 15:18:38,642 - INFO - Epoch [17/100], Train Loss: 0.4263, Train Top-1: 84.59%, Train Top-3: 98.26%, | Val Loss: 0.5003, Val Top-1: 83.25%, Val Top-3: 97.16%\n",
      "2025-04-20 15:18:59,053 - INFO - Epoch [18/100], Train Loss: 0.4379, Train Top-1: 84.36%, Train Top-3: 98.04%, | Val Loss: 0.4914, Val Top-1: 83.43%, Val Top-3: 97.33%\n",
      "2025-04-20 15:19:19,232 - INFO - Epoch [19/100], Train Loss: 0.4158, Train Top-1: 84.88%, Train Top-3: 98.27%, | Val Loss: 0.5215, Val Top-1: 82.50%, Val Top-3: 97.12%\n",
      "2025-04-20 15:19:39,440 - INFO - Epoch [20/100], Train Loss: 0.4432, Train Top-1: 83.91%, Train Top-3: 98.09%, | Val Loss: 0.4934, Val Top-1: 83.60%, Val Top-3: 97.35%\n",
      "2025-04-20 15:19:59,723 - INFO - Epoch [21/100], Train Loss: 0.3977, Train Top-1: 85.47%, Train Top-3: 98.50%, | Val Loss: 0.4781, Val Top-1: 83.46%, Val Top-3: 97.69%\n",
      "2025-04-20 15:20:20,013 - INFO - Epoch [22/100], Train Loss: 0.3738, Train Top-1: 86.31%, Train Top-3: 98.74%, | Val Loss: 0.4817, Val Top-1: 83.15%, Val Top-3: 97.49%\n",
      "2025-04-20 15:20:40,253 - INFO - Epoch [23/100], Train Loss: 0.4096, Train Top-1: 85.12%, Train Top-3: 98.39%, | Val Loss: 0.4739, Val Top-1: 84.01%, Val Top-3: 97.52%\n",
      "2025-04-20 15:21:00,395 - INFO - Epoch [24/100], Train Loss: 0.4052, Train Top-1: 85.29%, Train Top-3: 98.40%, | Val Loss: 0.4550, Val Top-1: 84.38%, Val Top-3: 97.87%\n",
      "2025-04-20 15:21:20,535 - INFO - Epoch [25/100], Train Loss: 0.3608, Train Top-1: 86.71%, Train Top-3: 98.84%, | Val Loss: 0.4527, Val Top-1: 84.40%, Val Top-3: 97.91%\n",
      "2025-04-20 15:21:40,714 - INFO - Epoch [26/100], Train Loss: 0.3869, Train Top-1: 85.78%, Train Top-3: 98.56%, | Val Loss: 0.4542, Val Top-1: 84.30%, Val Top-3: 97.82%\n",
      "2025-04-20 15:22:00,756 - INFO - Epoch [27/100], Train Loss: 0.3474, Train Top-1: 87.06%, Train Top-3: 98.99%, | Val Loss: 0.4549, Val Top-1: 84.84%, Val Top-3: 97.70%\n",
      "2025-04-20 15:22:20,888 - INFO - Epoch [28/100], Train Loss: 0.3367, Train Top-1: 87.34%, Train Top-3: 99.05%, | Val Loss: 0.4574, Val Top-1: 84.09%, Val Top-3: 97.80%\n",
      "2025-04-20 15:22:41,015 - INFO - Epoch [29/100], Train Loss: 0.3395, Train Top-1: 87.22%, Train Top-3: 99.02%, | Val Loss: 0.4346, Val Top-1: 85.84%, Val Top-3: 98.01%\n",
      "2025-04-20 15:23:01,082 - INFO - Epoch [30/100], Train Loss: 0.3201, Train Top-1: 87.77%, Train Top-3: 99.14%, | Val Loss: 0.4556, Val Top-1: 84.45%, Val Top-3: 97.77%\n",
      "2025-04-20 15:23:21,191 - INFO - Epoch [31/100], Train Loss: 0.3486, Train Top-1: 87.17%, Train Top-3: 98.86%, | Val Loss: 0.4426, Val Top-1: 84.79%, Val Top-3: 97.62%\n",
      "2025-04-20 15:23:41,197 - INFO - Epoch [32/100], Train Loss: 0.3220, Train Top-1: 87.91%, Train Top-3: 99.15%, | Val Loss: 0.4488, Val Top-1: 84.77%, Val Top-3: 97.74%\n",
      "2025-04-20 15:24:01,243 - INFO - Epoch [33/100], Train Loss: 0.3419, Train Top-1: 87.09%, Train Top-3: 98.95%, | Val Loss: 0.4464, Val Top-1: 83.93%, Val Top-3: 97.96%\n",
      "2025-04-20 15:24:21,351 - INFO - Epoch [34/100], Train Loss: 0.3283, Train Top-1: 87.63%, Train Top-3: 99.18%, | Val Loss: 0.4268, Val Top-1: 84.94%, Val Top-3: 98.17%\n",
      "2025-04-20 15:24:41,543 - INFO - Epoch [35/100], Train Loss: 0.2951, Train Top-1: 88.73%, Train Top-3: 99.40%, | Val Loss: 0.4510, Val Top-1: 85.18%, Val Top-3: 97.79%\n",
      "2025-04-20 15:25:01,776 - INFO - Epoch [36/100], Train Loss: 0.3269, Train Top-1: 87.80%, Train Top-3: 99.11%, | Val Loss: 0.4229, Val Top-1: 85.55%, Val Top-3: 98.06%\n",
      "2025-04-20 15:25:22,284 - INFO - Epoch [37/100], Train Loss: 0.2953, Train Top-1: 88.46%, Train Top-3: 99.42%, | Val Loss: 0.4323, Val Top-1: 85.35%, Val Top-3: 98.04%\n",
      "2025-04-20 15:25:42,493 - INFO - Epoch [38/100], Train Loss: 0.2841, Train Top-1: 89.04%, Train Top-3: 99.47%, | Val Loss: 0.4156, Val Top-1: 85.28%, Val Top-3: 98.00%\n",
      "2025-04-20 15:26:02,743 - INFO - Epoch [39/100], Train Loss: 0.3003, Train Top-1: 88.56%, Train Top-3: 99.33%, | Val Loss: 0.4205, Val Top-1: 85.26%, Val Top-3: 98.18%\n",
      "2025-04-20 15:26:23,042 - INFO - Epoch [40/100], Train Loss: 0.2983, Train Top-1: 88.49%, Train Top-3: 99.33%, | Val Loss: 0.4334, Val Top-1: 84.91%, Val Top-3: 97.99%\n",
      "2025-04-20 15:26:43,250 - INFO - Epoch [41/100], Train Loss: 0.3108, Train Top-1: 88.02%, Train Top-3: 99.21%, | Val Loss: 0.4187, Val Top-1: 85.77%, Val Top-3: 98.09%\n",
      "2025-04-20 15:27:03,394 - INFO - Epoch [42/100], Train Loss: 0.2800, Train Top-1: 89.15%, Train Top-3: 99.40%, | Val Loss: 0.4088, Val Top-1: 85.63%, Val Top-3: 98.24%\n",
      "2025-04-20 15:27:23,695 - INFO - Epoch [43/100], Train Loss: 0.2836, Train Top-1: 89.04%, Train Top-3: 99.48%, | Val Loss: 0.4137, Val Top-1: 85.59%, Val Top-3: 98.21%\n",
      "2025-04-20 15:27:43,901 - INFO - Epoch [44/100], Train Loss: 0.2832, Train Top-1: 89.02%, Train Top-3: 99.42%, | Val Loss: 0.4053, Val Top-1: 86.07%, Val Top-3: 98.20%\n",
      "2025-04-20 15:28:03,951 - INFO - Epoch [45/100], Train Loss: 0.2551, Train Top-1: 89.83%, Train Top-3: 99.62%, | Val Loss: 0.4112, Val Top-1: 86.18%, Val Top-3: 98.09%\n",
      "2025-04-20 15:28:24,026 - INFO - Epoch [46/100], Train Loss: 0.2574, Train Top-1: 89.90%, Train Top-3: 99.62%, | Val Loss: 0.4166, Val Top-1: 86.18%, Val Top-3: 98.27%\n",
      "2025-04-20 15:28:44,199 - INFO - Epoch [47/100], Train Loss: 0.2654, Train Top-1: 89.68%, Train Top-3: 99.55%, | Val Loss: 0.4040, Val Top-1: 86.00%, Val Top-3: 98.17%\n",
      "2025-04-20 15:29:04,402 - INFO - Epoch [48/100], Train Loss: 0.2531, Train Top-1: 90.10%, Train Top-3: 99.61%, | Val Loss: 0.4072, Val Top-1: 86.33%, Val Top-3: 98.35%\n",
      "2025-04-20 15:29:24,559 - INFO - Epoch [49/100], Train Loss: 0.2469, Train Top-1: 90.31%, Train Top-3: 99.68%, | Val Loss: 0.4047, Val Top-1: 86.23%, Val Top-3: 98.26%\n",
      "2025-04-20 15:29:44,647 - INFO - Epoch [50/100], Train Loss: 0.2384, Train Top-1: 90.62%, Train Top-3: 99.70%, | Val Loss: 0.4139, Val Top-1: 86.21%, Val Top-3: 98.27%\n",
      "2025-04-20 15:30:05,252 - INFO - Epoch [51/100], Train Loss: 0.2490, Train Top-1: 90.15%, Train Top-3: 99.63%, | Val Loss: 0.4065, Val Top-1: 86.79%, Val Top-3: 98.21%\n",
      "2025-04-20 15:30:25,720 - INFO - Epoch [52/100], Train Loss: 0.2375, Train Top-1: 90.68%, Train Top-3: 99.68%, | Val Loss: 0.4064, Val Top-1: 86.65%, Val Top-3: 98.24%\n",
      "2025-04-20 15:30:46,411 - INFO - Epoch [53/100], Train Loss: 0.2634, Train Top-1: 89.53%, Train Top-3: 99.52%, | Val Loss: 0.4103, Val Top-1: 86.79%, Val Top-3: 98.10%\n",
      "2025-04-20 15:31:07,824 - INFO - Epoch [54/100], Train Loss: 0.2378, Train Top-1: 90.50%, Train Top-3: 99.67%, | Val Loss: 0.4044, Val Top-1: 86.43%, Val Top-3: 98.38%\n",
      "2025-04-20 15:31:28,915 - INFO - Epoch [55/100], Train Loss: 0.2393, Train Top-1: 90.51%, Train Top-3: 99.70%, | Val Loss: 0.3980, Val Top-1: 86.78%, Val Top-3: 98.26%\n",
      "2025-04-20 15:31:49,677 - INFO - Epoch [56/100], Train Loss: 0.2131, Train Top-1: 91.33%, Train Top-3: 99.81%, | Val Loss: 0.4069, Val Top-1: 86.57%, Val Top-3: 98.55%\n",
      "2025-04-20 15:32:10,908 - INFO - Epoch [57/100], Train Loss: 0.2201, Train Top-1: 91.31%, Train Top-3: 99.77%, | Val Loss: 0.4056, Val Top-1: 86.99%, Val Top-3: 98.28%\n",
      "2025-04-20 15:32:31,634 - INFO - Epoch [58/100], Train Loss: 0.2130, Train Top-1: 91.48%, Train Top-3: 99.81%, | Val Loss: 0.4160, Val Top-1: 86.71%, Val Top-3: 98.35%\n",
      "2025-04-20 15:32:52,320 - INFO - Epoch [59/100], Train Loss: 0.2052, Train Top-1: 91.69%, Train Top-3: 99.86%, | Val Loss: 0.4158, Val Top-1: 86.55%, Val Top-3: 98.30%\n",
      "2025-04-20 15:33:12,996 - INFO - Epoch [60/100], Train Loss: 0.1994, Train Top-1: 92.00%, Train Top-3: 99.85%, | Val Loss: 0.4125, Val Top-1: 86.85%, Val Top-3: 98.50%\n",
      "2025-04-20 15:33:33,366 - INFO - Epoch [61/100], Train Loss: 0.2032, Train Top-1: 91.70%, Train Top-3: 99.84%, | Val Loss: 0.4152, Val Top-1: 86.81%, Val Top-3: 98.38%\n",
      "2025-04-20 15:33:53,639 - INFO - Epoch [62/100], Train Loss: 0.2201, Train Top-1: 91.32%, Train Top-3: 99.71%, | Val Loss: 0.4101, Val Top-1: 86.72%, Val Top-3: 98.33%\n",
      "2025-04-20 15:34:14,169 - INFO - Epoch [63/100], Train Loss: 0.2028, Train Top-1: 91.84%, Train Top-3: 99.81%, | Val Loss: 0.4051, Val Top-1: 86.99%, Val Top-3: 98.41%\n",
      "2025-04-20 15:34:35,179 - INFO - Epoch [64/100], Train Loss: 0.2066, Train Top-1: 91.56%, Train Top-3: 99.82%, | Val Loss: 0.4050, Val Top-1: 86.34%, Val Top-3: 98.33%\n",
      "2025-04-20 15:34:55,782 - INFO - Epoch [65/100], Train Loss: 0.2185, Train Top-1: 91.24%, Train Top-3: 99.74%, | Val Loss: 0.4015, Val Top-1: 86.41%, Val Top-3: 98.26%\n",
      "2025-04-20 15:35:16,779 - INFO - Epoch [66/100], Train Loss: 0.2042, Train Top-1: 91.85%, Train Top-3: 99.79%, | Val Loss: 0.3952, Val Top-1: 87.23%, Val Top-3: 98.51%\n",
      "2025-04-20 15:35:36,999 - INFO - Epoch [67/100], Train Loss: 0.1938, Train Top-1: 92.18%, Train Top-3: 99.84%, | Val Loss: 0.4011, Val Top-1: 86.87%, Val Top-3: 98.43%\n",
      "2025-04-20 15:35:57,594 - INFO - Epoch [68/100], Train Loss: 0.1845, Train Top-1: 92.38%, Train Top-3: 99.84%, | Val Loss: 0.4124, Val Top-1: 87.02%, Val Top-3: 98.31%\n",
      "2025-04-20 15:36:18,076 - INFO - Epoch [69/100], Train Loss: 0.1861, Train Top-1: 92.38%, Train Top-3: 99.87%, | Val Loss: 0.4077, Val Top-1: 86.94%, Val Top-3: 98.30%\n",
      "2025-04-20 15:36:38,728 - INFO - Epoch [70/100], Train Loss: 0.1811, Train Top-1: 92.67%, Train Top-3: 99.90%, | Val Loss: 0.4112, Val Top-1: 86.96%, Val Top-3: 98.41%\n",
      "2025-04-20 15:36:59,454 - INFO - Epoch [71/100], Train Loss: 0.1826, Train Top-1: 92.60%, Train Top-3: 99.87%, | Val Loss: 0.4146, Val Top-1: 86.94%, Val Top-3: 98.34%\n",
      "2025-04-20 15:37:20,961 - INFO - Epoch [72/100], Train Loss: 0.1770, Train Top-1: 92.78%, Train Top-3: 99.90%, | Val Loss: 0.4005, Val Top-1: 87.33%, Val Top-3: 98.54%\n",
      "2025-04-20 15:37:41,220 - INFO - Epoch [73/100], Train Loss: 0.1774, Train Top-1: 92.79%, Train Top-3: 99.90%, | Val Loss: 0.4099, Val Top-1: 86.99%, Val Top-3: 98.47%\n",
      "2025-04-20 15:38:02,045 - INFO - Epoch [74/100], Train Loss: 0.1780, Train Top-1: 92.86%, Train Top-3: 99.87%, | Val Loss: 0.4088, Val Top-1: 86.72%, Val Top-3: 98.51%\n",
      "2025-04-20 15:38:23,499 - INFO - Epoch [75/100], Train Loss: 0.1733, Train Top-1: 92.91%, Train Top-3: 99.88%, | Val Loss: 0.4067, Val Top-1: 86.71%, Val Top-3: 98.58%\n",
      "2025-04-20 15:38:44,638 - INFO - Epoch [76/100], Train Loss: 0.1716, Train Top-1: 93.04%, Train Top-3: 99.89%, | Val Loss: 0.4237, Val Top-1: 86.62%, Val Top-3: 98.41%\n",
      "2025-04-20 15:39:05,695 - INFO - Epoch [77/100], Train Loss: 0.1659, Train Top-1: 93.22%, Train Top-3: 99.91%, | Val Loss: 0.4116, Val Top-1: 87.09%, Val Top-3: 98.60%\n",
      "2025-04-20 15:39:28,413 - INFO - Epoch [78/100], Train Loss: 0.1600, Train Top-1: 93.45%, Train Top-3: 99.91%, | Val Loss: 0.4194, Val Top-1: 86.95%, Val Top-3: 98.54%\n",
      "2025-04-20 15:39:49,932 - INFO - Epoch [79/100], Train Loss: 0.1682, Train Top-1: 93.09%, Train Top-3: 99.89%, | Val Loss: 0.4174, Val Top-1: 86.75%, Val Top-3: 98.37%\n",
      "2025-04-20 15:40:10,431 - INFO - Epoch [80/100], Train Loss: 0.1598, Train Top-1: 93.40%, Train Top-3: 99.93%, | Val Loss: 0.4232, Val Top-1: 86.62%, Val Top-3: 98.45%\n",
      "2025-04-20 15:40:31,828 - INFO - Epoch [81/100], Train Loss: 0.1563, Train Top-1: 93.54%, Train Top-3: 99.95%, | Val Loss: 0.4142, Val Top-1: 86.94%, Val Top-3: 98.41%\n",
      "2025-04-20 15:40:52,745 - INFO - Epoch [82/100], Train Loss: 0.1525, Train Top-1: 93.56%, Train Top-3: 99.94%, | Val Loss: 0.4165, Val Top-1: 86.96%, Val Top-3: 98.57%\n",
      "2025-04-20 15:41:13,823 - INFO - Epoch [83/100], Train Loss: 0.1545, Train Top-1: 93.72%, Train Top-3: 99.93%, | Val Loss: 0.4255, Val Top-1: 86.62%, Val Top-3: 98.44%\n",
      "2025-04-20 15:41:34,553 - INFO - Epoch [84/100], Train Loss: 0.1533, Train Top-1: 93.72%, Train Top-3: 99.93%, | Val Loss: 0.4132, Val Top-1: 87.09%, Val Top-3: 98.40%\n",
      "2025-04-20 15:41:55,400 - INFO - Epoch [85/100], Train Loss: 0.1523, Train Top-1: 93.72%, Train Top-3: 99.95%, | Val Loss: 0.4231, Val Top-1: 87.05%, Val Top-3: 98.38%\n",
      "2025-04-20 15:42:15,990 - INFO - Epoch [86/100], Train Loss: 0.1477, Train Top-1: 94.02%, Train Top-3: 99.95%, | Val Loss: 0.4263, Val Top-1: 86.79%, Val Top-3: 98.43%\n",
      "2025-04-20 15:42:36,782 - INFO - Epoch [87/100], Train Loss: 0.1462, Train Top-1: 94.06%, Train Top-3: 99.93%, | Val Loss: 0.4234, Val Top-1: 87.04%, Val Top-3: 98.41%\n",
      "2025-04-20 15:42:57,460 - INFO - Epoch [88/100], Train Loss: 0.1470, Train Top-1: 93.98%, Train Top-3: 99.93%, | Val Loss: 0.4232, Val Top-1: 87.05%, Val Top-3: 98.44%\n",
      "2025-04-20 15:43:21,357 - INFO - Epoch [89/100], Train Loss: 0.1468, Train Top-1: 93.94%, Train Top-3: 99.96%, | Val Loss: 0.4124, Val Top-1: 86.96%, Val Top-3: 98.58%\n",
      "2025-04-20 15:43:46,864 - INFO - Epoch [90/100], Train Loss: 0.1422, Train Top-1: 94.03%, Train Top-3: 99.92%, | Val Loss: 0.4191, Val Top-1: 86.82%, Val Top-3: 98.62%\n",
      "2025-04-20 15:44:10,981 - INFO - Epoch [91/100], Train Loss: 0.1431, Train Top-1: 94.13%, Train Top-3: 99.96%, | Val Loss: 0.4277, Val Top-1: 86.85%, Val Top-3: 98.27%\n",
      "2025-04-20 15:44:32,177 - INFO - Epoch [92/100], Train Loss: 0.1430, Train Top-1: 94.17%, Train Top-3: 99.96%, | Val Loss: 0.4150, Val Top-1: 87.39%, Val Top-3: 98.40%\n",
      "2025-04-20 15:44:52,666 - INFO - Epoch [93/100], Train Loss: 0.1424, Train Top-1: 93.99%, Train Top-3: 99.95%, | Val Loss: 0.4293, Val Top-1: 86.89%, Val Top-3: 98.37%\n",
      "2025-04-20 15:45:13,117 - INFO - Epoch [94/100], Train Loss: 0.1420, Train Top-1: 94.05%, Train Top-3: 99.94%, | Val Loss: 0.4315, Val Top-1: 86.91%, Val Top-3: 98.37%\n",
      "2025-04-20 15:45:33,338 - INFO - Epoch [95/100], Train Loss: 0.1418, Train Top-1: 94.25%, Train Top-3: 99.96%, | Val Loss: 0.4323, Val Top-1: 87.11%, Val Top-3: 98.34%\n",
      "2025-04-20 15:45:53,283 - INFO - Epoch [96/100], Train Loss: 0.1424, Train Top-1: 94.14%, Train Top-3: 99.95%, | Val Loss: 0.4287, Val Top-1: 86.58%, Val Top-3: 98.34%\n",
      "2025-04-20 15:46:13,104 - INFO - Epoch [97/100], Train Loss: 0.1404, Train Top-1: 94.27%, Train Top-3: 99.95%, | Val Loss: 0.4273, Val Top-1: 86.79%, Val Top-3: 98.48%\n",
      "2025-04-20 15:46:33,104 - INFO - Epoch [98/100], Train Loss: 0.1402, Train Top-1: 94.24%, Train Top-3: 99.93%, | Val Loss: 0.4236, Val Top-1: 87.40%, Val Top-3: 98.50%\n",
      "2025-04-20 15:46:52,943 - INFO - Epoch [99/100], Train Loss: 0.1389, Train Top-1: 94.17%, Train Top-3: 99.96%, | Val Loss: 0.4206, Val Top-1: 87.29%, Val Top-3: 98.34%\n",
      "2025-04-20 15:47:13,280 - INFO - Epoch [100/100], Train Loss: 0.1359, Train Top-1: 94.40%, Train Top-3: 99.96%, | Val Loss: 0.4332, Val Top-1: 86.74%, Val Top-3: 98.47%\n",
      "2025-04-20 15:47:13,281 - INFO - Training finished.\n",
      "2025-04-20 15:47:13,317 - INFO - Final model saved to best_model.pth\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import base64\n",
    "import os\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from openai import OpenAI\n",
    "\n",
    "# 初始化客户端\n",
    "client = OpenAI(\n",
    "    api_key=\"api\",  # 替换为您的ModelScope SDK Token\n",
    "    base_url=\"https://api-inference.modelscope.cn/v1\"\n",
    ")\n",
    "\n",
    "def analyze_image(image_path):\n",
    "    \"\"\"单张图片分析函数\"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as file:\n",
    "            encoded_file = base64.b64encode(file.read()).decode(\"utf-8\")\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"Qwen/Qwen2.5-VL-72B-Instruct\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful and harmless assistant.\"}],\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\"url\": f\"data:image/png;base64,{encoded_file}\"}\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": \"\"\"（保持原prompt内容不变）\"\"\"\n",
    "                        }\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            stream=False  # 关闭流式输出以提高并发效率\n",
    "        )\n",
    "\n",
    "        # 提取分析结果\n",
    "        result = response.choices[0].message.content\n",
    "        return {\n",
    "            \"image_path\": image_path,\n",
    "            \"result\": result.strip(\"---\\n\").strip()  # 清理格式标记\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"处理 {image_path} 时出错: {str(e)}\")\n",
    "        return {\"image_path\": image_path, \"error\": str(e)}\n",
    "\n",
    "def batch_process(folder_path, output_file=\"results.json\", max_workers=3):\n",
    "    \"\"\"批量处理文件夹内所有图片\"\"\"\n",
    "    # 获取所有图片文件（支持jpg/png）\n",
    "    image_files = [\n",
    "        os.path.join(folder_path, f)\n",
    "        for f in os.listdir(folder_path)\n",
    "        if f.lower().endswith(('.jpg', '.png'))\n",
    "    ]\n",
    "\n",
    "    print(f\"发现 {len(image_files)} 张待处理图片\")\n",
    "\n",
    "    # 并发处理（3线程）\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(analyze_image, img) for img in image_files]\n",
    "        for future in futures:\n",
    "            results.append(future.result())\n",
    "\n",
    "    # 保存结果\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"结果已保存至 {output_file}\")\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    batch_process(\"train/高风险\")  # 处理该文件夹内所有图片"
   ],
   "id": "832e6b05acd5770a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T06:38:44.720737Z",
     "start_time": "2025-04-20T06:38:40.977060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 推理\n",
    "\n",
    "top1_acc, top3_acc, inference_speed = evaluate_model(cnn, test_loader, device)\n",
    "print(f\"Top-1 Accuracy: {top1_acc:.4f}\")\n",
    "print(f\"Top-3 Accuracy: {top3_acc:.4f}\")\n",
    "print(f\"Inference Speed: {inference_speed * 1000:.4f} ms per sample\")"
   ],
   "id": "44445d68673d35ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 86.8227\n",
      "Top-3 Accuracy: 98.7234\n",
      "Inference Speed: 0.0448 ms per sample\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T06:38:44.727742Z",
     "start_time": "2025-04-20T06:38:44.723728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将推理得出的数据(正确率、速度)保存\n",
    "with open('results/results.txt', 'w') as f:\n",
    "    f.write(f\"Top-1 Accuracy: {top1_acc:.4f}\\n\")\n",
    "    f.write(f\"Top-3 Accuracy: {top3_acc:.4f}\\n\")\n",
    "    f.write(f\"Inference Speed: {inference_speed * 1000:.4f} ms per sample\\n\")"
   ],
   "id": "ef724979f89c3d49",
   "outputs": [],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
