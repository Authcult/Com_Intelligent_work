{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 基于卷积神经网络的手写英文字母识别系统研究",
   "id": "b551c4d99781975b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 准备数据集及数据预处理",
   "id": "e00af614c8239f67"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 将下载的数据集按类重命名",
   "id": "a0cd9383cb350d27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T01:16:55.541599900Z",
     "start_time": "2025-04-16T01:16:22.928508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "import os\n",
    "import string\n",
    "\n",
    "# 定义源目录路径\n",
    "source_dir = \"EnglishImg/English/Img/GoodImg/Bmp\"\n",
    "\n",
    "# 生成目标文件夹名称列表\n",
    "target_folders = list(string.digits) + list(string.ascii_uppercase) + [f\"{char}_\" for char in string.ascii_lowercase]\n",
    "\n",
    "# 获取源目录下的所有文件夹名称\n",
    "source_folders = sorted([f for f in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, f))])\n",
    "\n",
    "# 确保源文件夹数量与目标文件夹数量一致\n",
    "if len(source_folders) != len(target_folders):\n",
    "    raise ValueError(\"源文件夹数量与目标文件夹数量不一致\")\n",
    "\n",
    "# 重命名文件夹\n",
    "for source_folder, target_folder in zip(source_folders, target_folders):\n",
    "    source_path = os.path.join(source_dir, source_folder)\n",
    "    target_path = os.path.join(source_dir, target_folder)\n",
    "\n",
    "    try:\n",
    "        os.rename(source_path, target_path)\n",
    "        print(f\"重命名: {source_path} -> {target_path}\")\n",
    "    except FileExistsError:\n",
    "        print(f\"目标文件夹 {target_path} 已存在，跳过重命名 {source_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"重命名 {source_path} 到 {target_path} 时出错: {e}\")\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ],
   "id": "1895206fac195157",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nimport string\\n\\n# 定义源目录路径\\nsource_dir = \"EnglishImg/English/Img/GoodImg/Bmp\"\\n\\n# 生成目标文件夹名称列表\\ntarget_folders = list(string.digits) + list(string.ascii_uppercase) + [f\"{char}_\" for char in string.ascii_lowercase]\\n\\n# 获取源目录下的所有文件夹名称\\nsource_folders = sorted([f for f in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, f))])\\n\\n# 确保源文件夹数量与目标文件夹数量一致\\nif len(source_folders) != len(target_folders):\\n    raise ValueError(\"源文件夹数量与目标文件夹数量不一致\")\\n\\n# 重命名文件夹\\nfor source_folder, target_folder in zip(source_folders, target_folders):\\n    source_path = os.path.join(source_dir, source_folder)\\n    target_path = os.path.join(source_dir, target_folder)\\n\\n    try:\\n        os.rename(source_path, target_path)\\n        print(f\"重命名: {source_path} -> {target_path}\")\\n    except FileExistsError:\\n        print(f\"目标文件夹 {target_path} 已存在，跳过重命名 {source_path}\")\\n    except Exception as e:\\n        print(f\"重命名 {source_path} 到 {target_path} 时出错: {e}\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 划分训练集和测试集",
   "id": "58d8c82b646071be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T01:16:55.541599900Z",
     "start_time": "2025-04-16T01:16:22.939761Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6ef556d0909a59ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-16T01:17:01.205575Z",
     "start_time": "2025-04-16T01:16:57.954579Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.models as models\n",
    "from torchvision import utils\n",
    "import torchvision.transforms as T\n",
    "import torch.utils.data as Data\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "#使用tensorboardX进行可视化\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "#参数定义\n",
    "EPOCH = 100\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-4\n",
    "ROOT_DIR = \"EnglishImg/English/Img/GoodImg/Bmp\"\n",
    "LOG_DIR = f\"runs/handwriting_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "MODEL_SAVE_PATH = \"cnn_res_attention_best.pth\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T01:17:02.307980Z",
     "start_time": "2025-04-16T01:17:02.298904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义数据预处理变换\n",
    "transform = T.Compose([\n",
    "    T.Resize((28, 28)), # 统一尺寸为28x28\n",
    "    T.Grayscale(num_output_channels=1), # 灰度处理\n",
    "    T.RandomRotation(15),  # 数据增强：随机旋转\n",
    "    T.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 位移\n",
    "    T.ToTensor(), # 转换为Tensor\n",
    "    # 如果需要标准化，可以取消注释以下行\n",
    "    T.Normalize([0.5], [0.5])\n",
    "])\n",
    "# 定义划分数据集的函数\n",
    "def split_dataset(root_dir, transform, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, batch_size=128, shuffle=True, random_seed=42):\n",
    "    \"\"\"\n",
    "    划分数据集为训练集、验证集和测试集，并返回对应的DataLoader。\n",
    "\n",
    "    参数:\n",
    "    - root_dir: 数据集根目录\n",
    "    - transform: 数据预处理变换\n",
    "    - train_ratio: 训练集比例\n",
    "    - val_ratio: 验证集比例\n",
    "    - test_ratio: 测试集比例\n",
    "    - batch_size: 批次大小\n",
    "    - shuffle: 是否打乱数据\n",
    "    - random_seed: 随机种子，用于保证结果可重复\n",
    "\n",
    "    返回:\n",
    "    - train_loader: 训练集DataLoader\n",
    "    - val_loader: 验证集DataLoader\n",
    "    - test_loader: 测试集DataLoader\n",
    "    - full_dataset: 原始的ImageFolder数据集\n",
    "    \"\"\"\n",
    "    # 确保比例之和为1\n",
    "    assert train_ratio + val_ratio + test_ratio == 1, \"比例之和必须为1\"\n",
    "\n",
    "    # 加载整个数据集\n",
    "    full_dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "\n",
    "    # 计算每个子集的大小\n",
    "    dataset_size = len(full_dataset)\n",
    "    train_size = int(train_ratio * dataset_size)\n",
    "    val_size = int(val_ratio * dataset_size)\n",
    "    test_size = dataset_size - train_size - val_size\n",
    "\n",
    "    # 随机划分数据集\n",
    "    train_dataset, val_dataset, test_dataset = Data.random_split(full_dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(random_seed))\n",
    "\n",
    "    # 创建DataLoader\n",
    "    train_loader = Data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    val_loader = Data.DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    test_loader = Data.DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, full_dataset\n",
    "\n"
   ],
   "id": "fc494049419e614",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T01:17:05.336367Z",
     "start_time": "2025-04-16T01:17:05.232416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用函数划分数据集\n",
    "train_loader, val_loader, test_loader, full_dataset = split_dataset(\n",
    "    root_dir=\"EnglishImg/English/Img/GoodImg/Bmp\",\n",
    "    transform=transform,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# 打印数据集大小\n",
    "print(f\"训练集大小: {len(train_loader.dataset)}\")\n",
    "print(f\"验证集大小: {len(val_loader.dataset)}\")\n",
    "print(f\"测试集大小: {len(test_loader.dataset)}\")\n",
    "\n",
    "# 获取类别数量\n",
    "label_num = len(full_dataset.class_to_idx)\n",
    "\n",
    "# 数据可视化\n",
    "to_img = T.ToPILImage()\n",
    "a = to_img(train_loader.dataset[0][0])  # size=[1, 28, 28]\n",
    "plt.imshow(a)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 定义CNN模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.Conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.Conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.Linear = nn.Sequential(\n",
    "            nn.Linear(32*7*7, 400),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, label_num),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.Conv1(input)\n",
    "        input = self.Conv2(input)\n",
    "        input = input.view(input.size(0), -1)\n",
    "        output = self.Linear(input)\n",
    "        return output\n",
    "\n",
    "cnn = CNN()\n",
    "print(cnn)\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "# 定义损失函数\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "id": "68bd896fbdea9d62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 5393\n",
      "验证集大小: 1155\n",
      "测试集大小: 1157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (Conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (Conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (Linear): Sequential(\n",
      "    (0): Linear(in_features=1568, out_features=400, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=400, out_features=80, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=80, out_features=62, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T01:17:12.205928Z",
     "start_time": "2025-04-16T01:17:12.201742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 轻量CNN结构？\n",
    "class SimpleAttention(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels // 2, 1)\n",
    "        self.conv2 = nn.Conv2d(channels // 2, channels, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn = self.conv1(x)\n",
    "        attn = self.conv2(attn)\n",
    "        attn = self.sigmoid(attn)\n",
    "        return x * attn\n"
   ],
   "id": "dd59129f03cb4ec9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T01:17:13.844548Z",
     "start_time": "2025-04-16T01:17:13.833029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 添加残差模块\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_attention=False):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        self.attn = SimpleAttention(out_channels) if use_attention else nn.Identity()\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.shortcut(x)\n",
    "        out = self.conv(x)\n",
    "        out = self.attn(out)\n",
    "        return self.relu(out + res)"
   ],
   "id": "8d893488a7be1899",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T01:17:16.180183Z",
     "start_time": "2025-04-16T01:17:16.173730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CNN自注意力模块？\n",
    "class SelfAttention2D(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.query = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.key   = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.value = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))  # 可学习的缩放系数\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        proj_q = self.query(x).view(B, -1, H * W)          # B x C1 x N\n",
    "        proj_k = self.key(x).view(B, -1, H * W)            # B x C1 x N\n",
    "        proj_v = self.value(x).view(B, -1, H * W)          # B x C  x N\n",
    "\n",
    "        attention = torch.bmm(proj_q.permute(0, 2, 1), proj_k)  # B x N x N\n",
    "        attention = torch.softmax(attention, dim=-1)\n",
    "\n",
    "        out = torch.bmm(proj_v, attention.permute(0, 2, 1))     # B x C x N\n",
    "        out = out.view(B, C, H, W)\n",
    "\n",
    "        return self.gamma * out + x\n",
    "\n",
    "class CNNWithAttention(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)  # 28x28 → 14x14\n",
    "        )\n",
    "        self.block1 = ResidualBlock(32, 64, use_attention=True)\n",
    "        self.block2 = ResidualBlock(64, 128, use_attention=True)\n",
    "        self.pool = nn.MaxPool2d(2)  # 14x14 → 7x7\n",
    "        self.block3 = ResidualBlock(128, 128)\n",
    "        self.attention = SelfAttention2D(128) # 添加自注意力模块\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.block3(x)\n",
    "        return self.classifier(x)\n",
    "\n"
   ],
   "id": "1fbdb56d08290183",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T01:17:22.062503Z",
     "start_time": "2025-04-16T01:17:22.048726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练与验证函数\n",
    "def train_and_validate(model, train_loader, val_loader, epochs, device='cpu', save_path='best_model.pth'):\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    writer = SummaryWriter(log_dir=LOG_DIR)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_x)\n",
    "            loss = loss_func(outputs, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "\n",
    "        train_acc = correct / total\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_x, val_y in val_loader:\n",
    "                val_x, val_y = val_x.to(device), val_y.to(device)\n",
    "                val_outputs = model(val_x)\n",
    "                _, val_pred = torch.max(val_outputs, 1)\n",
    "                val_correct += (val_pred == val_y).sum().item()\n",
    "                val_total += val_y.size(0)\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n",
    "        writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
    "        writer.add_scalar(\"Accuracy/val\", val_acc, epoch)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Loss: {avg_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"✅ 最佳模型已保存，Val Acc: {val_acc:.4f}\")\n",
    "        sys.stdout.flush()  # 强制刷新缓冲区，立即输出\n",
    "    writer.close()\n"
   ],
   "id": "83d9f46bd66acfee",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T02:30:07.541835700Z",
     "start_time": "2025-04-16T01:17:25.066321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"当前使用设备: {device}\")\n",
    "\n",
    "    train_loader, val_loader, test_loader, full_dataset = split_dataset(\n",
    "        root_dir=ROOT_DIR,\n",
    "        transform=transform,\n",
    "        train_ratio=0.7,\n",
    "        val_ratio=0.15,\n",
    "        test_ratio=0.15,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        random_seed=42\n",
    "    )\n",
    "\n",
    "    print(f\"训练集大小: {len(train_loader.dataset)}\")\n",
    "    print(f\"验证集大小: {len(val_loader.dataset)}\")\n",
    "    print(f\"测试集大小: {len(test_loader.dataset)}\")\n",
    "\n",
    "    label_num = len(full_dataset.class_to_idx)\n",
    "    model = CNNWithAttention(label_num) # 调用模型\n",
    "\n",
    "    train_and_validate(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=EPOCH,\n",
    "        device=device,\n",
    "        save_path=MODEL_SAVE_PATH\n",
    "    )\n",
    "\n",
    "    print(\"训练结束。\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "423e70d579e78269",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用设备: cpu\n",
      "训练集大小: 5393\n",
      "验证集大小: 1155\n",
      "测试集大小: 1157\n",
      "Epoch [1/100] Loss: 4.0295, Train Acc: 0.0751, Val Acc: 0.0866\n",
      "✅ 最佳模型已保存，Val Acc: 0.0866\n",
      "Epoch [2/100] Loss: 3.8137, Train Acc: 0.1322, Val Acc: 0.1524\n",
      "✅ 最佳模型已保存，Val Acc: 0.1524\n",
      "Epoch [3/100] Loss: 3.5923, Train Acc: 0.1810, Val Acc: 0.1974\n",
      "✅ 最佳模型已保存，Val Acc: 0.1974\n",
      "Epoch [4/100] Loss: 3.3746, Train Acc: 0.2268, Val Acc: 0.2294\n",
      "✅ 最佳模型已保存，Val Acc: 0.2294\n",
      "Epoch [5/100] Loss: 3.1827, Train Acc: 0.2691, Val Acc: 0.2753\n",
      "✅ 最佳模型已保存，Val Acc: 0.2753\n",
      "Epoch [6/100] Loss: 2.9899, Train Acc: 0.3184, Val Acc: 0.3143\n",
      "✅ 最佳模型已保存，Val Acc: 0.3143\n",
      "Epoch [7/100] Loss: 2.8213, Train Acc: 0.3484, Val Acc: 0.3221\n",
      "✅ 最佳模型已保存，Val Acc: 0.3221\n",
      "Epoch [8/100] Loss: 2.6879, Train Acc: 0.3625, Val Acc: 0.3602\n",
      "✅ 最佳模型已保存，Val Acc: 0.3602\n",
      "Epoch [9/100] Loss: 2.5526, Train Acc: 0.3918, Val Acc: 0.3671\n",
      "✅ 最佳模型已保存，Val Acc: 0.3671\n",
      "Epoch [10/100] Loss: 2.4208, Train Acc: 0.4144, Val Acc: 0.3913\n",
      "✅ 最佳模型已保存，Val Acc: 0.3913\n",
      "Epoch [11/100] Loss: 2.3188, Train Acc: 0.4363, Val Acc: 0.3913\n",
      "Epoch [12/100] Loss: 2.2142, Train Acc: 0.4652, Val Acc: 0.4442\n",
      "✅ 最佳模型已保存，Val Acc: 0.4442\n",
      "Epoch [13/100] Loss: 2.1363, Train Acc: 0.4843, Val Acc: 0.4545\n",
      "✅ 最佳模型已保存，Val Acc: 0.4545\n",
      "Epoch [14/100] Loss: 2.0473, Train Acc: 0.5060, Val Acc: 0.4762\n",
      "✅ 最佳模型已保存，Val Acc: 0.4762\n",
      "Epoch [15/100] Loss: 1.9459, Train Acc: 0.5327, Val Acc: 0.5152\n",
      "✅ 最佳模型已保存，Val Acc: 0.5152\n",
      "Epoch [16/100] Loss: 1.8988, Train Acc: 0.5550, Val Acc: 0.5100\n",
      "Epoch [17/100] Loss: 1.7986, Train Acc: 0.5726, Val Acc: 0.5290\n",
      "✅ 最佳模型已保存，Val Acc: 0.5290\n",
      "Epoch [18/100] Loss: 1.7264, Train Acc: 0.5848, Val Acc: 0.5489\n",
      "✅ 最佳模型已保存，Val Acc: 0.5489\n",
      "Epoch [19/100] Loss: 1.6672, Train Acc: 0.5958, Val Acc: 0.5541\n",
      "✅ 最佳模型已保存，Val Acc: 0.5541\n",
      "Epoch [20/100] Loss: 1.6143, Train Acc: 0.6082, Val Acc: 0.5844\n",
      "✅ 最佳模型已保存，Val Acc: 0.5844\n",
      "Epoch [21/100] Loss: 1.5344, Train Acc: 0.6249, Val Acc: 0.5636\n",
      "Epoch [22/100] Loss: 1.4759, Train Acc: 0.6464, Val Acc: 0.5870\n",
      "✅ 最佳模型已保存，Val Acc: 0.5870\n",
      "Epoch [23/100] Loss: 1.4383, Train Acc: 0.6473, Val Acc: 0.5974\n",
      "✅ 最佳模型已保存，Val Acc: 0.5974\n",
      "Epoch [24/100] Loss: 1.3713, Train Acc: 0.6607, Val Acc: 0.6208\n",
      "✅ 最佳模型已保存，Val Acc: 0.6208\n",
      "Epoch [25/100] Loss: 1.3230, Train Acc: 0.6711, Val Acc: 0.6355\n",
      "✅ 最佳模型已保存，Val Acc: 0.6355\n",
      "Epoch [26/100] Loss: 1.2991, Train Acc: 0.6724, Val Acc: 0.6364\n",
      "✅ 最佳模型已保存，Val Acc: 0.6364\n",
      "Epoch [27/100] Loss: 1.2408, Train Acc: 0.6898, Val Acc: 0.6303\n",
      "Epoch [28/100] Loss: 1.2059, Train Acc: 0.6948, Val Acc: 0.6511\n",
      "✅ 最佳模型已保存，Val Acc: 0.6511\n",
      "Epoch [29/100] Loss: 1.1578, Train Acc: 0.7052, Val Acc: 0.6641\n",
      "✅ 最佳模型已保存，Val Acc: 0.6641\n",
      "Epoch [30/100] Loss: 1.1290, Train Acc: 0.7091, Val Acc: 0.6667\n",
      "✅ 最佳模型已保存，Val Acc: 0.6667\n",
      "Epoch [31/100] Loss: 1.0975, Train Acc: 0.7195, Val Acc: 0.6580\n",
      "Epoch [32/100] Loss: 1.0666, Train Acc: 0.7220, Val Acc: 0.6537\n",
      "Epoch [33/100] Loss: 1.0217, Train Acc: 0.7345, Val Acc: 0.6424\n",
      "Epoch [34/100] Loss: 1.0095, Train Acc: 0.7343, Val Acc: 0.6745\n",
      "✅ 最佳模型已保存，Val Acc: 0.6745\n",
      "Epoch [35/100] Loss: 0.9766, Train Acc: 0.7406, Val Acc: 0.6797\n",
      "✅ 最佳模型已保存，Val Acc: 0.6797\n",
      "Epoch [36/100] Loss: 0.9613, Train Acc: 0.7521, Val Acc: 0.6554\n",
      "Epoch [37/100] Loss: 0.9333, Train Acc: 0.7610, Val Acc: 0.6935\n",
      "✅ 最佳模型已保存，Val Acc: 0.6935\n",
      "Epoch [38/100] Loss: 0.9530, Train Acc: 0.7469, Val Acc: 0.6701\n",
      "Epoch [39/100] Loss: 0.9175, Train Acc: 0.7625, Val Acc: 0.6788\n",
      "Epoch [40/100] Loss: 0.8715, Train Acc: 0.7667, Val Acc: 0.6935\n",
      "Epoch [41/100] Loss: 0.8343, Train Acc: 0.7803, Val Acc: 0.6710\n",
      "Epoch [42/100] Loss: 0.8162, Train Acc: 0.7823, Val Acc: 0.7100\n",
      "✅ 最佳模型已保存，Val Acc: 0.7100\n",
      "Epoch [43/100] Loss: 0.8020, Train Acc: 0.7886, Val Acc: 0.6874\n",
      "Epoch [44/100] Loss: 0.7790, Train Acc: 0.7890, Val Acc: 0.7325\n",
      "✅ 最佳模型已保存，Val Acc: 0.7325\n",
      "Epoch [45/100] Loss: 0.7614, Train Acc: 0.8003, Val Acc: 0.7056\n",
      "Epoch [46/100] Loss: 0.7452, Train Acc: 0.8033, Val Acc: 0.7126\n",
      "Epoch [47/100] Loss: 0.7289, Train Acc: 0.8051, Val Acc: 0.7281\n",
      "Epoch [48/100] Loss: 0.7276, Train Acc: 0.8114, Val Acc: 0.7325\n",
      "Epoch [49/100] Loss: 0.6984, Train Acc: 0.8157, Val Acc: 0.7255\n",
      "Epoch [50/100] Loss: 0.6801, Train Acc: 0.8192, Val Acc: 0.7290\n",
      "Epoch [51/100] Loss: 0.6609, Train Acc: 0.8225, Val Acc: 0.7143\n",
      "Epoch [52/100] Loss: 0.6404, Train Acc: 0.8251, Val Acc: 0.7558\n",
      "✅ 最佳模型已保存，Val Acc: 0.7558\n",
      "Epoch [53/100] Loss: 0.6381, Train Acc: 0.8348, Val Acc: 0.7307\n",
      "Epoch [54/100] Loss: 0.6331, Train Acc: 0.8340, Val Acc: 0.7411\n",
      "Epoch [55/100] Loss: 0.6113, Train Acc: 0.8370, Val Acc: 0.7558\n",
      "Epoch [56/100] Loss: 0.5904, Train Acc: 0.8465, Val Acc: 0.7593\n",
      "✅ 最佳模型已保存，Val Acc: 0.7593\n",
      "Epoch [57/100] Loss: 0.5997, Train Acc: 0.8392, Val Acc: 0.7169\n",
      "Epoch [58/100] Loss: 0.5664, Train Acc: 0.8498, Val Acc: 0.7403\n",
      "Epoch [59/100] Loss: 0.5621, Train Acc: 0.8515, Val Acc: 0.7333\n",
      "Epoch [60/100] Loss: 0.5666, Train Acc: 0.8498, Val Acc: 0.7610\n",
      "✅ 最佳模型已保存，Val Acc: 0.7610\n",
      "Epoch [61/100] Loss: 0.5377, Train Acc: 0.8548, Val Acc: 0.7325\n",
      "Epoch [62/100] Loss: 0.5333, Train Acc: 0.8576, Val Acc: 0.7688\n",
      "✅ 最佳模型已保存，Val Acc: 0.7688\n",
      "Epoch [63/100] Loss: 0.5256, Train Acc: 0.8602, Val Acc: 0.7610\n",
      "Epoch [64/100] Loss: 0.4948, Train Acc: 0.8683, Val Acc: 0.7749\n",
      "✅ 最佳模型已保存，Val Acc: 0.7749\n",
      "Epoch [65/100] Loss: 0.4822, Train Acc: 0.8685, Val Acc: 0.7567\n",
      "Epoch [66/100] Loss: 0.4747, Train Acc: 0.8683, Val Acc: 0.7602\n",
      "Epoch [67/100] Loss: 0.4674, Train Acc: 0.8748, Val Acc: 0.7541\n",
      "Epoch [68/100] Loss: 0.4524, Train Acc: 0.8836, Val Acc: 0.7688\n",
      "Epoch [69/100] Loss: 0.4710, Train Acc: 0.8702, Val Acc: 0.7558\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7ee70f27438a6b63"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
