{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 基于卷积神经网络的手写英文字母识别系统研究",
   "id": "b551c4d99781975b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 准备数据集及数据预处理",
   "id": "e00af614c8239f67"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 将下载的数据集按类重命名",
   "id": "a0cd9383cb350d27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T14:15:49.570025Z",
     "start_time": "2025-04-16T14:15:49.563513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "import os\n",
    "import string\n",
    "\n",
    "# 定义源目录路径\n",
    "source_dir = \"EnglishImg/English/Img/GoodImg/Bmp\"\n",
    "\n",
    "# 生成目标文件夹名称列表\n",
    "target_folders = list(string.digits) + list(string.ascii_uppercase) + [f\"{char}_\" for char in string.ascii_lowercase]\n",
    "\n",
    "# 获取源目录下的所有文件夹名称\n",
    "source_folders = sorted([f for f in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, f))])\n",
    "\n",
    "# 确保源文件夹数量与目标文件夹数量一致\n",
    "if len(source_folders) != len(target_folders):\n",
    "    raise ValueError(\"源文件夹数量与目标文件夹数量不一致\")\n",
    "\n",
    "# 重命名文件夹\n",
    "for source_folder, target_folder in zip(source_folders, target_folders):\n",
    "    source_path = os.path.join(source_dir, source_folder)\n",
    "    target_path = os.path.join(source_dir, target_folder)\n",
    "\n",
    "    try:\n",
    "        os.rename(source_path, target_path)\n",
    "        print(f\"重命名: {source_path} -> {target_path}\")\n",
    "    except FileExistsError:\n",
    "        print(f\"目标文件夹 {target_path} 已存在，跳过重命名 {source_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"重命名 {source_path} 到 {target_path} 时出错: {e}\")\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ],
   "id": "1895206fac195157",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nimport string\\n\\n# 定义源目录路径\\nsource_dir = \"EnglishImg/English/Img/GoodImg/Bmp\"\\n\\n# 生成目标文件夹名称列表\\ntarget_folders = list(string.digits) + list(string.ascii_uppercase) + [f\"{char}_\" for char in string.ascii_lowercase]\\n\\n# 获取源目录下的所有文件夹名称\\nsource_folders = sorted([f for f in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, f))])\\n\\n# 确保源文件夹数量与目标文件夹数量一致\\nif len(source_folders) != len(target_folders):\\n    raise ValueError(\"源文件夹数量与目标文件夹数量不一致\")\\n\\n# 重命名文件夹\\nfor source_folder, target_folder in zip(source_folders, target_folders):\\n    source_path = os.path.join(source_dir, source_folder)\\n    target_path = os.path.join(source_dir, target_folder)\\n\\n    try:\\n        os.rename(source_path, target_path)\\n        print(f\"重命名: {source_path} -> {target_path}\")\\n    except FileExistsError:\\n        print(f\"目标文件夹 {target_path} 已存在，跳过重命名 {source_path}\")\\n    except Exception as e:\\n        print(f\"重命名 {source_path} 到 {target_path} 时出错: {e}\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 划分训练集和测试集",
   "id": "58d8c82b646071be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T14:15:49.576427Z",
     "start_time": "2025-04-16T14:15:49.570025Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6ef556d0909a59ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-16T14:15:52.784175Z",
     "start_time": "2025-04-16T14:15:49.694229Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.models as models\n",
    "from torchvision import utils\n",
    "import torchvision.transforms as T\n",
    "import torch.utils.data as Data\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "#使用tensorboardX进行可视化\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "#参数定义\n",
    "EPOCH = 100\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-4\n",
    "ROOT_DIR = \"EnglishImg/English/Img/GoodImg/Bmp\"\n",
    "LOG_DIR = f\"runs/handwriting_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "MODEL_SAVE_PATH = \"cnn_res_attention_best.pth\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T14:15:52.801286Z",
     "start_time": "2025-04-16T14:15:52.794585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义数据预处理变换\n",
    "transform = T.Compose([\n",
    "    T.Resize((36, 36)), # 统一尺寸为28x28\n",
    "    T.Grayscale(num_output_channels=1), # 灰度处理\n",
    "    T.RandomRotation(20),  # 数据增强：随机旋转\n",
    "    T.RandomAffine(degrees=0, translate=(0.15, 0.15)),  # 位移\n",
    "    T.RandomHorizontalFlip(),  # 增加横向翻转\n",
    "    T.ToTensor(), # 转换为Tensor\n",
    "    # 如果需要标准化，可以取消注释以下行\n",
    "    T.Normalize([0.5], [0.5])\n",
    "])\n",
    "# 定义划分数据集的函数\n",
    "def split_dataset(root_dir, transform, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, batch_size=128, shuffle=True, random_seed=42):\n",
    "    \"\"\"\n",
    "    划分数据集为训练集、验证集和测试集，并返回对应的DataLoader。\n",
    "\n",
    "    参数:\n",
    "    - root_dir: 数据集根目录\n",
    "    - transform: 数据预处理变换\n",
    "    - train_ratio: 训练集比例\n",
    "    - val_ratio: 验证集比例\n",
    "    - test_ratio: 测试集比例\n",
    "    - batch_size: 批次大小\n",
    "    - shuffle: 是否打乱数据\n",
    "    - random_seed: 随机种子，用于保证结果可重复\n",
    "\n",
    "    返回:\n",
    "    - train_loader: 训练集DataLoader\n",
    "    - val_loader: 验证集DataLoader\n",
    "    - test_loader: 测试集DataLoader\n",
    "    - full_dataset: 原始的ImageFolder数据集\n",
    "    \"\"\"\n",
    "    # 确保比例之和为1\n",
    "    assert train_ratio + val_ratio + test_ratio == 1, \"比例之和必须为1\"\n",
    "\n",
    "    # 加载整个数据集\n",
    "    full_dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "\n",
    "    # 计算每个子集的大小\n",
    "    dataset_size = len(full_dataset)\n",
    "    train_size = int(train_ratio * dataset_size)\n",
    "    val_size = int(val_ratio * dataset_size)\n",
    "    test_size = dataset_size - train_size - val_size\n",
    "\n",
    "    # 随机划分数据集\n",
    "    train_dataset, val_dataset, test_dataset = Data.random_split(full_dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(random_seed))\n",
    "\n",
    "    # 创建DataLoader\n",
    "    train_loader = Data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    val_loader = Data.DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    test_loader = Data.DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, full_dataset\n",
    "\n"
   ],
   "id": "fc494049419e614",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T14:15:52.908286Z",
     "start_time": "2025-04-16T14:15:52.807280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用函数划分数据集\n",
    "train_loader, val_loader, test_loader, full_dataset = split_dataset(\n",
    "    root_dir=\"EnglishImg/English/Img/GoodImg/Bmp\",\n",
    "    transform=transform,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# 打印数据集大小\n",
    "print(f\"训练集大小: {len(train_loader.dataset)}\")\n",
    "print(f\"验证集大小: {len(val_loader.dataset)}\")\n",
    "print(f\"测试集大小: {len(test_loader.dataset)}\")\n",
    "\n",
    "# 获取类别数量\n",
    "label_num = len(full_dataset.class_to_idx)\n",
    "\n",
    "# 数据可视化\n",
    "to_img = T.ToPILImage()\n",
    "a = to_img(train_loader.dataset[0][0])  # size=[1, 28, 28]\n",
    "plt.imshow(a)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 定义CNN模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.Conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.Conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.Linear = nn.Sequential(\n",
    "            nn.Linear(32*9*9, 400),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, label_num),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.Conv1(input)\n",
    "        input = self.Conv2(input)\n",
    "        input = input.view(input.size(0), -1)\n",
    "        output = self.Linear(input)\n",
    "        return output\n",
    "\n",
    "cnn = CNN()\n",
    "print(cnn)\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "# 定义损失函数\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "id": "68bd896fbdea9d62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 5393\n",
      "验证集大小: 1155\n",
      "测试集大小: 1157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (Conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (Conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (Linear): Sequential(\n",
      "    (0): Linear(in_features=2592, out_features=400, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=400, out_features=80, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=80, out_features=62, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T14:15:52.924688Z",
     "start_time": "2025-04-16T14:15:52.914949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 轻量CNN结构？\n",
    "class SimpleAttention(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels // 2, 1)\n",
    "        self.conv2 = nn.Conv2d(channels // 2, channels, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn = self.conv1(x)\n",
    "        attn = self.conv2(attn)\n",
    "        attn = self.sigmoid(attn)\n",
    "        return x * attn\n"
   ],
   "id": "dd59129f03cb4ec9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T14:15:52.953427Z",
     "start_time": "2025-04-16T14:15:52.948129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 添加残差模块\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_attention=False):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        self.attn = SimpleAttention(out_channels) if use_attention else nn.Identity()\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.shortcut(x)\n",
    "        out = self.conv(x)\n",
    "        out = self.attn(out)\n",
    "        return self.relu(out + res)"
   ],
   "id": "8d893488a7be1899",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T14:15:52.963272Z",
     "start_time": "2025-04-16T14:15:52.954944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CNN自注意力模块？\n",
    "class SelfAttention2D(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.query = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.key   = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.value = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))  # 可学习的缩放系数\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        proj_q = self.query(x).view(B, -1, H * W)          # B x C1 x N\n",
    "        proj_k = self.key(x).view(B, -1, H * W)            # B x C1 x N\n",
    "        proj_v = self.value(x).view(B, -1, H * W)          # B x C  x N\n",
    "\n",
    "        attention = torch.bmm(proj_q.permute(0, 2, 1), proj_k)  # B x N x N\n",
    "        attention = torch.softmax(attention, dim=-1)\n",
    "\n",
    "        out = torch.bmm(proj_v, attention.permute(0, 2, 1))     # B x C x N\n",
    "        out = out.view(B, C, H, W)\n",
    "\n",
    "        return self.gamma * out + x\n",
    "\n",
    "class CNNWithAttention(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.MaxPool2d(2)  # 28x28 → 14x14\n",
    "        )\n",
    "        self.block1 = ResidualBlock(64, 128, use_attention=True)\n",
    "        self.block2 = ResidualBlock(128, 256, use_attention=True)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.block3 = ResidualBlock(256, 256)\n",
    "        self.attention = SelfAttention2D(256) # 添加自注意力模块\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.attention(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.block3(x)\n",
    "        return self.classifier(x)\n",
    "\n"
   ],
   "id": "1fbdb56d08290183",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T14:15:52.975630Z",
     "start_time": "2025-04-16T14:15:52.968688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练与验证函数\n",
    "def train_and_validate(model, train_loader, val_loader, epochs, device='cpu', save_path='best_model.pth'):\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    writer = SummaryWriter(log_dir=LOG_DIR)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_x)\n",
    "            loss = loss_func(outputs, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "\n",
    "        train_acc = correct / total\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_x, val_y in val_loader:\n",
    "                val_x, val_y = val_x.to(device), val_y.to(device)\n",
    "                val_outputs = model(val_x)\n",
    "                _, val_pred = torch.max(val_outputs, 1)\n",
    "                val_correct += (val_pred == val_y).sum().item()\n",
    "                val_total += val_y.size(0)\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n",
    "        writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
    "        writer.add_scalar(\"Accuracy/val\", val_acc, epoch)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Loss: {avg_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"✅ 最佳模型已保存，Val Acc: {val_acc:.4f}\")\n",
    "        sys.stdout.flush()  # 强制刷新缓冲区，立即输出\n",
    "    writer.close()\n"
   ],
   "id": "83d9f46bd66acfee",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-16T14:15:52.987979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"当前使用设备: {device}\")\n",
    "\n",
    "    train_loader, val_loader, test_loader, full_dataset = split_dataset(\n",
    "        root_dir=ROOT_DIR,\n",
    "        transform=transform,\n",
    "        train_ratio=0.7,\n",
    "        val_ratio=0.15,\n",
    "        test_ratio=0.15,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        random_seed=42\n",
    "    )\n",
    "\n",
    "    print(f\"训练集大小: {len(train_loader.dataset)}\")\n",
    "    print(f\"验证集大小: {len(val_loader.dataset)}\")\n",
    "    print(f\"测试集大小: {len(test_loader.dataset)}\")\n",
    "\n",
    "    label_num = len(full_dataset.class_to_idx)\n",
    "    model = CNNWithAttention(label_num) # 调用模型\n",
    "\n",
    "    train_and_validate(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=EPOCH,\n",
    "        device=device,\n",
    "        save_path=MODEL_SAVE_PATH\n",
    "    )\n",
    "\n",
    "    print(\"训练结束。\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "423e70d579e78269",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用设备: cpu\n",
      "训练集大小: 5393\n",
      "验证集大小: 1155\n",
      "测试集大小: 1157\n",
      "Epoch [1/100] Loss: 4.0466, Train Acc: 0.0571, Val Acc: 0.0649\n",
      "✅ 最佳模型已保存，Val Acc: 0.0649\n",
      "Epoch [2/100] Loss: 3.8167, Train Acc: 0.1118, Val Acc: 0.1108\n",
      "✅ 最佳模型已保存，Val Acc: 0.1108\n",
      "Epoch [3/100] Loss: 3.5906, Train Acc: 0.1700, Val Acc: 0.2069\n",
      "✅ 最佳模型已保存，Val Acc: 0.2069\n",
      "Epoch [4/100] Loss: 3.3635, Train Acc: 0.2169, Val Acc: 0.2000\n",
      "Epoch [5/100] Loss: 3.1945, Train Acc: 0.2596, Val Acc: 0.2087\n",
      "✅ 最佳模型已保存，Val Acc: 0.2087\n",
      "Epoch [6/100] Loss: 3.0253, Train Acc: 0.2926, Val Acc: 0.2398\n",
      "✅ 最佳模型已保存，Val Acc: 0.2398\n",
      "Epoch [7/100] Loss: 2.8643, Train Acc: 0.3217, Val Acc: 0.2771\n",
      "✅ 最佳模型已保存，Val Acc: 0.2771\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T14:26:28.592748100Z",
     "start_time": "2025-04-16T03:11:29.777136Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7ee70f27438a6b63",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
