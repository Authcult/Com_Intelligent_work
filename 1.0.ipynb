{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 基于卷积神经网络的手写英文字母识别系统研究"
   ],
   "id": "4a81bab4fc2874a0"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from utils import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-22T12:38:11.839088Z",
     "start_time": "2025-04-22T12:38:08.389779800Z"
    }
   },
   "id": "fe7d0d5c421bd823"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 基本参数设置"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fb410f8d5211185"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ROOT_DIR = \"emnist_png_balanced\"  # 数据集路径\n",
    "BATCH_SIZE = 256  # 批大小\n",
    "EPOCH = 500  # 训练轮数\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")# 设备选择\n",
    "LR = 1e-4  # 学习率"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a980bf7d08696ec2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 加入数据增强"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cf25880ff1af13f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform = AlbumentationsTransform()  # 使用数据增强\n",
    "\n",
    "train_loader, val_loader, test_loader, full_dataset = split_dataset(\n",
    "    root_dir=ROOT_DIR,\n",
    "    transform=transform,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# 打印数据集大小\n",
    "print(f\"训练集大小: {len(train_loader.dataset)}\")\n",
    "print(f\"验证集大小: {len(val_loader.dataset)}\")\n",
    "print(f\"测试集大小: {len(test_loader.dataset)}\")\n",
    "\n",
    "# 获取类别数量\n",
    "label_num = len(full_dataset.class_to_idx)\n",
    "\n",
    "# 数据可视化\n",
    "to_img = T.ToPILImage()\n",
    "a = to_img(train_loader.dataset[0][0])  # size=[1, 32, 32]\n",
    "plt.imshow(a)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4135cc6208ce7555"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 训练模型（有注意力机制）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "894957acff6814f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CNNWithAttention(label_num, use_attention=True) # 调用模型\n",
    "print(model)\n",
    "\n",
    "train_and_validate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCH,\n",
    "    device=device,\n",
    "    save_path=\"cnn_res_attention_aug_best.pth\",\n",
    ")\n",
    "\n",
    "print(\"训练结束。\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54ba1f9b4d87e022"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 训练模型（无注意力机制）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d59eda74ec7e2f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CNNWithAttention(label_num, use_attention=False) # 调用模型\n",
    "\n",
    "train_and_validate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCH,\n",
    "    device=device,\n",
    "    save_path=\"cnn_res_noattention_aug_best.pth\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8adde905a16102ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 无数据增强"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "513531a9b038a88a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T12:38:12.052355Z",
     "start_time": "2025-04-22T12:38:11.842187700Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集每个类别样本数：\n",
      "类别 A: 1400\n",
      "类别 B: 1400\n",
      "类别 C: 1400\n",
      "类别 D: 1400\n",
      "类别 E: 1400\n",
      "类别 F: 1400\n",
      "类别 G: 1400\n",
      "类别 H: 1400\n",
      "类别 I: 1400\n",
      "类别 J: 1400\n",
      "类别 K: 1400\n",
      "类别 L: 1400\n",
      "类别 M: 1400\n",
      "类别 N: 1400\n",
      "类别 O: 1400\n",
      "类别 P: 1400\n",
      "类别 Q: 1400\n",
      "类别 R: 1400\n",
      "类别 S: 1400\n",
      "类别 T: 1400\n",
      "类别 U: 1400\n",
      "类别 V: 1400\n",
      "类别 W: 1400\n",
      "类别 X: 1400\n",
      "类别 Y: 1400\n",
      "类别 Z: 1400\n",
      "类别 a_: 1400\n",
      "类别 b_: 1400\n",
      "类别 d_: 1400\n",
      "类别 e_: 1400\n",
      "类别 f_: 1400\n",
      "类别 g_: 1400\n",
      "类别 h_: 1400\n",
      "类别 n_: 1400\n",
      "类别 q_: 1400\n",
      "类别 r_: 1400\n",
      "类别 t_: 1400\n",
      "\n",
      "验证集每个类别样本数：\n",
      "类别 A: 300\n",
      "类别 B: 300\n",
      "类别 C: 300\n",
      "类别 D: 300\n",
      "类别 E: 300\n",
      "类别 F: 300\n",
      "类别 G: 300\n",
      "类别 H: 300\n",
      "类别 I: 300\n",
      "类别 J: 300\n",
      "类别 K: 300\n",
      "类别 L: 300\n",
      "类别 M: 300\n",
      "类别 N: 300\n",
      "类别 O: 300\n",
      "类别 P: 300\n",
      "类别 Q: 300\n",
      "类别 R: 300\n",
      "类别 S: 300\n",
      "类别 T: 300\n",
      "类别 U: 300\n",
      "类别 V: 300\n",
      "类别 W: 300\n",
      "类别 X: 300\n",
      "类别 Y: 300\n",
      "类别 Z: 300\n",
      "类别 a_: 300\n",
      "类别 b_: 300\n",
      "类别 d_: 300\n",
      "类别 e_: 300\n",
      "类别 f_: 300\n",
      "类别 g_: 300\n",
      "类别 h_: 300\n",
      "类别 n_: 300\n",
      "类别 q_: 300\n",
      "类别 r_: 300\n",
      "类别 t_: 300\n",
      "\n",
      "测试集每个类别样本数：\n",
      "类别 A: 300\n",
      "类别 B: 300\n",
      "类别 C: 300\n",
      "类别 D: 300\n",
      "类别 E: 300\n",
      "类别 F: 300\n",
      "类别 G: 300\n",
      "类别 H: 300\n",
      "类别 I: 300\n",
      "类别 J: 300\n",
      "类别 K: 300\n",
      "类别 L: 300\n",
      "类别 M: 300\n",
      "类别 N: 300\n",
      "类别 O: 300\n",
      "类别 P: 300\n",
      "类别 Q: 300\n",
      "类别 R: 300\n",
      "类别 S: 300\n",
      "类别 T: 300\n",
      "类别 U: 300\n",
      "类别 V: 300\n",
      "类别 W: 300\n",
      "类别 X: 300\n",
      "类别 Y: 300\n",
      "类别 Z: 300\n",
      "类别 a_: 300\n",
      "类别 b_: 300\n",
      "类别 d_: 300\n",
      "类别 e_: 300\n",
      "类别 f_: 300\n",
      "类别 g_: 300\n",
      "类别 h_: 300\n",
      "类别 n_: 300\n",
      "类别 q_: 300\n",
      "类别 r_: 300\n",
      "类别 t_: 300\n",
      "训练集大小: 51800\n",
      "验证集大小: 11100\n",
      "测试集大小: 11100\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2,
   "source": [
    "transform = AlbumentationsTransformBase()  # 不使用数据增强\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader, full_dataset = split_dataset(\n",
    "    root_dir=ROOT_DIR,\n",
    "    transform=transform,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "# 打印数据集大小\n",
    "print(f\"训练集大小: {len(train_loader.dataset)}\")\n",
    "print(f\"验证集大小: {len(val_loader.dataset)}\")\n",
    "print(f\"测试集大小: {len(test_loader.dataset)}\")\n",
    "\n",
    "# 获取类别数量\n",
    "label_num = len(full_dataset.class_to_idx)\n",
    "\n",
    "# 数据可视化\n",
    "to_img = T.ToPILImage()\n",
    "a = to_img(train_loader.dataset[0][0])  # size=[1, 32, 32]\n",
    "plt.imshow(a)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "528581b0e00270be"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 训练模型（有注意力机制）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7c13ca7478fad9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T12:51:27.383088100Z",
     "start_time": "2025-04-22T12:38:12.050339900Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500] Loss: 3.3567, Train Top-1 Acc: 0.1270, Train Top-3 Acc: 0.2883, Val Top-1 Acc: 0.3254, Val Top-3 Acc: 0.6117\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.3254\n",
      "Epoch [2/500] Loss: 2.4861, Train Top-1 Acc: 0.3602, Train Top-3 Acc: 0.6502, Val Top-1 Acc: 0.5970, Val Top-3 Acc: 0.8549\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.5970\n",
      "Epoch [3/500] Loss: 1.7093, Train Top-1 Acc: 0.5488, Train Top-3 Acc: 0.8339, Val Top-1 Acc: 0.7262, Val Top-3 Acc: 0.9159\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.7262\n",
      "Epoch [4/500] Loss: 1.2004, Train Top-1 Acc: 0.6759, Train Top-3 Acc: 0.9086, Val Top-1 Acc: 0.7819, Val Top-3 Acc: 0.9462\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.7819\n",
      "Epoch [5/500] Loss: 0.8945, Train Top-1 Acc: 0.7550, Train Top-3 Acc: 0.9389, Val Top-1 Acc: 0.8289, Val Top-3 Acc: 0.9566\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.8289\n",
      "Epoch [6/500] Loss: 0.7080, Train Top-1 Acc: 0.8016, Train Top-3 Acc: 0.9539, Val Top-1 Acc: 0.8457, Val Top-3 Acc: 0.9661\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.8457\n",
      "Epoch [7/500] Loss: 0.6043, Train Top-1 Acc: 0.8248, Train Top-3 Acc: 0.9625, Val Top-1 Acc: 0.8324, Val Top-3 Acc: 0.9621\n",
      "Epoch [8/500] Loss: 0.5258, Train Top-1 Acc: 0.8438, Train Top-3 Acc: 0.9693, Val Top-1 Acc: 0.8569, Val Top-3 Acc: 0.9702\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.8569\n",
      "Epoch [9/500] Loss: 0.4820, Train Top-1 Acc: 0.8534, Train Top-3 Acc: 0.9725, Val Top-1 Acc: 0.8701, Val Top-3 Acc: 0.9715\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.8701\n",
      "Epoch [10/500] Loss: 0.4391, Train Top-1 Acc: 0.8667, Train Top-3 Acc: 0.9763, Val Top-1 Acc: 0.8743, Val Top-3 Acc: 0.9747\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.8743\n",
      "Epoch [11/500] Loss: 0.4128, Train Top-1 Acc: 0.8724, Train Top-3 Acc: 0.9781, Val Top-1 Acc: 0.8736, Val Top-3 Acc: 0.9740\n",
      "Epoch [12/500] Loss: 0.3880, Train Top-1 Acc: 0.8795, Train Top-3 Acc: 0.9801, Val Top-1 Acc: 0.8711, Val Top-3 Acc: 0.9748\n",
      "Epoch [13/500] Loss: 0.3695, Train Top-1 Acc: 0.8846, Train Top-3 Acc: 0.9815, Val Top-1 Acc: 0.8677, Val Top-3 Acc: 0.9723\n",
      "Epoch [14/500] Loss: 0.3503, Train Top-1 Acc: 0.8893, Train Top-3 Acc: 0.9833, Val Top-1 Acc: 0.8887, Val Top-3 Acc: 0.9786\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.8887\n",
      "Epoch [15/500] Loss: 0.3343, Train Top-1 Acc: 0.8941, Train Top-3 Acc: 0.9846, Val Top-1 Acc: 0.8667, Val Top-3 Acc: 0.9713\n",
      "Epoch [16/500] Loss: 0.3204, Train Top-1 Acc: 0.8968, Train Top-3 Acc: 0.9858, Val Top-1 Acc: 0.8807, Val Top-3 Acc: 0.9759\n",
      "Epoch [17/500] Loss: 0.3056, Train Top-1 Acc: 0.8999, Train Top-3 Acc: 0.9867, Val Top-1 Acc: 0.8896, Val Top-3 Acc: 0.9785\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.8896\n",
      "Epoch [18/500] Loss: 0.2965, Train Top-1 Acc: 0.9038, Train Top-3 Acc: 0.9875, Val Top-1 Acc: 0.8868, Val Top-3 Acc: 0.9775\n",
      "Epoch [19/500] Loss: 0.2865, Train Top-1 Acc: 0.9075, Train Top-3 Acc: 0.9882, Val Top-1 Acc: 0.8697, Val Top-3 Acc: 0.9737\n",
      "Epoch [20/500] Loss: 0.2780, Train Top-1 Acc: 0.9093, Train Top-3 Acc: 0.9894, Val Top-1 Acc: 0.8914, Val Top-3 Acc: 0.9801\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.8914\n",
      "Epoch [21/500] Loss: 0.2667, Train Top-1 Acc: 0.9125, Train Top-3 Acc: 0.9902, Val Top-1 Acc: 0.8884, Val Top-3 Acc: 0.9779\n",
      "Epoch [22/500] Loss: 0.2600, Train Top-1 Acc: 0.9140, Train Top-3 Acc: 0.9904, Val Top-1 Acc: 0.8877, Val Top-3 Acc: 0.9776\n",
      "Epoch [23/500] Loss: 0.2532, Train Top-1 Acc: 0.9158, Train Top-3 Acc: 0.9910, Val Top-1 Acc: 0.8848, Val Top-3 Acc: 0.9791\n",
      "Epoch [24/500] Loss: 0.2470, Train Top-1 Acc: 0.9182, Train Top-3 Acc: 0.9914, Val Top-1 Acc: 0.8898, Val Top-3 Acc: 0.9798\n",
      "Epoch [25/500] Loss: 0.2409, Train Top-1 Acc: 0.9195, Train Top-3 Acc: 0.9923, Val Top-1 Acc: 0.8959, Val Top-3 Acc: 0.9811\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.8959\n",
      "Epoch [26/500] Loss: 0.2331, Train Top-1 Acc: 0.9225, Train Top-3 Acc: 0.9922, Val Top-1 Acc: 0.8890, Val Top-3 Acc: 0.9786\n",
      "Epoch [27/500] Loss: 0.2275, Train Top-1 Acc: 0.9226, Train Top-3 Acc: 0.9925, Val Top-1 Acc: 0.8895, Val Top-3 Acc: 0.9814\n",
      "Epoch [28/500] Loss: 0.2189, Train Top-1 Acc: 0.9256, Train Top-3 Acc: 0.9933, Val Top-1 Acc: 0.8900, Val Top-3 Acc: 0.9797\n",
      "Epoch [29/500] Loss: 0.2141, Train Top-1 Acc: 0.9271, Train Top-3 Acc: 0.9940, Val Top-1 Acc: 0.8966, Val Top-3 Acc: 0.9817\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.8966\n",
      "Epoch [30/500] Loss: 0.2063, Train Top-1 Acc: 0.9286, Train Top-3 Acc: 0.9944, Val Top-1 Acc: 0.8957, Val Top-3 Acc: 0.9811\n",
      "Epoch [31/500] Loss: 0.2073, Train Top-1 Acc: 0.9281, Train Top-3 Acc: 0.9939, Val Top-1 Acc: 0.8997, Val Top-3 Acc: 0.9828\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.8997\n",
      "Epoch [32/500] Loss: 0.1984, Train Top-1 Acc: 0.9309, Train Top-3 Acc: 0.9949, Val Top-1 Acc: 0.8887, Val Top-3 Acc: 0.9789\n",
      "Epoch [33/500] Loss: 0.1978, Train Top-1 Acc: 0.9308, Train Top-3 Acc: 0.9947, Val Top-1 Acc: 0.8953, Val Top-3 Acc: 0.9819\n",
      "Epoch [34/500] Loss: 0.1956, Train Top-1 Acc: 0.9311, Train Top-3 Acc: 0.9944, Val Top-1 Acc: 0.8771, Val Top-3 Acc: 0.9762\n",
      "Epoch [35/500] Loss: 0.1925, Train Top-1 Acc: 0.9321, Train Top-3 Acc: 0.9951, Val Top-1 Acc: 0.8800, Val Top-3 Acc: 0.9759\n",
      "Epoch [36/500] Loss: 0.1831, Train Top-1 Acc: 0.9359, Train Top-3 Acc: 0.9958, Val Top-1 Acc: 0.8933, Val Top-3 Acc: 0.9791\n",
      "Epoch [37/500] Loss: 0.1860, Train Top-1 Acc: 0.9346, Train Top-3 Acc: 0.9956, Val Top-1 Acc: 0.9016, Val Top-3 Acc: 0.9821\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.9016\n",
      "Epoch [38/500] Loss: 0.1775, Train Top-1 Acc: 0.9379, Train Top-3 Acc: 0.9959, Val Top-1 Acc: 0.8982, Val Top-3 Acc: 0.9827\n",
      "Epoch [39/500] Loss: 0.1745, Train Top-1 Acc: 0.9388, Train Top-3 Acc: 0.9965, Val Top-1 Acc: 0.8852, Val Top-3 Acc: 0.9790\n",
      "Epoch [40/500] Loss: 0.1663, Train Top-1 Acc: 0.9413, Train Top-3 Acc: 0.9969, Val Top-1 Acc: 0.8964, Val Top-3 Acc: 0.9819\n",
      "Epoch [41/500] Loss: 0.1662, Train Top-1 Acc: 0.9408, Train Top-3 Acc: 0.9967, Val Top-1 Acc: 0.8895, Val Top-3 Acc: 0.9803\n",
      "Epoch [42/500] Loss: 0.1629, Train Top-1 Acc: 0.9417, Train Top-3 Acc: 0.9965, Val Top-1 Acc: 0.8920, Val Top-3 Acc: 0.9804\n",
      "Epoch [43/500] Loss: 0.1654, Train Top-1 Acc: 0.9398, Train Top-3 Acc: 0.9966, Val Top-1 Acc: 0.8891, Val Top-3 Acc: 0.9814\n",
      "Epoch [44/500] Loss: 0.1577, Train Top-1 Acc: 0.9444, Train Top-3 Acc: 0.9966, Val Top-1 Acc: 0.8893, Val Top-3 Acc: 0.9791\n",
      "Epoch [45/500] Loss: 0.1539, Train Top-1 Acc: 0.9446, Train Top-3 Acc: 0.9973, Val Top-1 Acc: 0.8922, Val Top-3 Acc: 0.9811\n",
      "Epoch [46/500] Loss: 0.1512, Train Top-1 Acc: 0.9464, Train Top-3 Acc: 0.9973, Val Top-1 Acc: 0.8861, Val Top-3 Acc: 0.9807\n",
      "Epoch [47/500] Loss: 0.1462, Train Top-1 Acc: 0.9471, Train Top-3 Acc: 0.9979, Val Top-1 Acc: 0.8859, Val Top-3 Acc: 0.9786\n",
      "Epoch [48/500] Loss: 0.1430, Train Top-1 Acc: 0.9478, Train Top-3 Acc: 0.9975, Val Top-1 Acc: 0.8918, Val Top-3 Acc: 0.9805\n",
      "Epoch [49/500] Loss: 0.1450, Train Top-1 Acc: 0.9477, Train Top-3 Acc: 0.9973, Val Top-1 Acc: 0.8871, Val Top-3 Acc: 0.9799\n",
      "Epoch [50/500] Loss: 0.1417, Train Top-1 Acc: 0.9489, Train Top-3 Acc: 0.9977, Val Top-1 Acc: 0.8923, Val Top-3 Acc: 0.9805\n",
      "Epoch [51/500] Loss: 0.1380, Train Top-1 Acc: 0.9498, Train Top-3 Acc: 0.9977, Val Top-1 Acc: 0.8952, Val Top-3 Acc: 0.9825\n",
      "Epoch [52/500] Loss: 0.1393, Train Top-1 Acc: 0.9489, Train Top-3 Acc: 0.9978, Val Top-1 Acc: 0.8912, Val Top-3 Acc: 0.9815\n",
      "⏳ 验证集Top-1准确率在连续 15 轮未提升，训练提前终止。\n"
     ]
    }
   ],
   "execution_count": 3,
   "source": [
    "model = CNNWithAttention(label_num, use_attention=True) # 调用模型\n",
    "\n",
    "train_and_validate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCH,\n",
    "    device=device,\n",
    "    save_path=\"cnn_res_attention_noaug_best.pth\",\n",
    "    lr=LR\n",
    ")"
   ],
   "id": "b9f066ea01c8bf57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 训练模型（无注意力机制）"
   ],
   "id": "63732b390e9bf460"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T12:53:07.562057500Z",
     "start_time": "2025-04-22T12:51:27.379101300Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500] Loss: 3.2437, Train Top-1 Acc: 0.1448, Train Top-3 Acc: 0.3228, Val Top-1 Acc: 0.3361, Val Top-3 Acc: 0.6219\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.3361\n",
      "Epoch [2/500] Loss: 2.2866, Train Top-1 Acc: 0.4052, Train Top-3 Acc: 0.6936, Val Top-1 Acc: 0.6611, Val Top-3 Acc: 0.9039\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.6611\n",
      "Epoch [3/500] Loss: 1.6008, Train Top-1 Acc: 0.5959, Train Top-3 Acc: 0.8607, Val Top-1 Acc: 0.7779, Val Top-3 Acc: 0.9395\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.7779\n",
      "Epoch [4/500] Loss: 1.2008, Train Top-1 Acc: 0.6847, Train Top-3 Acc: 0.9084, Val Top-1 Acc: 0.8205, Val Top-3 Acc: 0.9552\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.8205\n",
      "Epoch [5/500] Loss: 0.9859, Train Top-1 Acc: 0.7309, Train Top-3 Acc: 0.9274, Val Top-1 Acc: 0.8343, Val Top-3 Acc: 0.9588\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.8343\n",
      "Epoch [6/500] Loss: 0.8548, Train Top-1 Acc: 0.7585, Train Top-3 Acc: 0.9393, Val Top-1 Acc: 0.8510, Val Top-3 Acc: 0.9652\n",
      "✅ 新的最佳模型已保存，Val Top-1 Acc: 0.8510\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m CNNWithAttention(label_num, use_attention\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;66;03m# 调用模型\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m train_and_validate(\n\u001B[0;32m      4\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m      5\u001B[0m     train_loader\u001B[38;5;241m=\u001B[39mtrain_loader,\n\u001B[0;32m      6\u001B[0m     val_loader\u001B[38;5;241m=\u001B[39mval_loader,\n\u001B[0;32m      7\u001B[0m     epochs\u001B[38;5;241m=\u001B[39mEPOCH,\n\u001B[0;32m      8\u001B[0m     device\u001B[38;5;241m=\u001B[39mdevice,\n\u001B[0;32m      9\u001B[0m     save_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcnn_res_noattention_noaug_best.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     10\u001B[0m     lr\u001B[38;5;241m=\u001B[39mLR\n\u001B[0;32m     11\u001B[0m )\n",
      "File \u001B[1;32mE:\\computational_intelligence\\Com_Intelligent_work\\utils.py:429\u001B[0m, in \u001B[0;36mtrain_and_validate\u001B[1;34m(model, train_loader, val_loader, epochs, device, save_path, save_best_only, patience, auto_lr, lr, LOG_DIR)\u001B[0m\n\u001B[0;32m    426\u001B[0m total \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    428\u001B[0m \u001B[38;5;66;03m# --- 训练阶段 ---\u001B[39;00m\n\u001B[1;32m--> 429\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_x, batch_y \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m    430\u001B[0m     batch_x, batch_y \u001B[38;5;241m=\u001B[39m batch_x\u001B[38;5;241m.\u001B[39mto(device), batch_y\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m    432\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model(batch_x)\n",
      "File \u001B[1;32mD:\\condaenv\\.conda\\envs\\Compy12\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    707\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 708\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[0;32m    709\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    710\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    711\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    712\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    713\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    714\u001B[0m ):\n",
      "File \u001B[1;32mD:\\condaenv\\.conda\\envs\\Compy12\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    762\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    763\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 764\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    765\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    766\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mD:\\condaenv\\.conda\\envs\\Compy12\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__getitems__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__:\n\u001B[1;32m---> 50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "File \u001B[1;32mD:\\condaenv\\.conda\\envs\\Compy12\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001B[0m, in \u001B[0;36mSubset.__getitems__\u001B[1;34m(self, indices)\u001B[0m\n\u001B[0;32m    418\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    419\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 420\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx]] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[1;32mD:\\condaenv\\.conda\\envs\\Compy12\\Lib\\site-packages\\torchvision\\datasets\\folder.py:245\u001B[0m, in \u001B[0;36mDatasetFolder.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    237\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    238\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m    239\u001B[0m \u001B[38;5;124;03m    index (int): Index\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    242\u001B[0m \u001B[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001B[39;00m\n\u001B[0;32m    243\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    244\u001B[0m path, target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples[index]\n\u001B[1;32m--> 245\u001B[0m sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader(path)\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    247\u001B[0m     sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(sample)\n",
      "File \u001B[1;32mD:\\condaenv\\.conda\\envs\\Compy12\\Lib\\site-packages\\torchvision\\datasets\\folder.py:284\u001B[0m, in \u001B[0;36mdefault_loader\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m    282\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m accimage_loader(path)\n\u001B[0;32m    283\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 284\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pil_loader(path)\n",
      "File \u001B[1;32mD:\\condaenv\\.conda\\envs\\Compy12\\Lib\\site-packages\\torchvision\\datasets\\folder.py:262\u001B[0m, in \u001B[0;36mpil_loader\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpil_loader\u001B[39m(path: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Image\u001B[38;5;241m.\u001B[39mImage:\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;66;03m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001B[39;00m\n\u001B[1;32m--> 262\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m    263\u001B[0m         img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(f)\n\u001B[0;32m    264\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m img\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4,
   "source": [
    "model = CNNWithAttention(label_num, use_attention=False) # 调用模型\n",
    "\n",
    "train_and_validate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCH,\n",
    "    device=device,\n",
    "    save_path=\"cnn_res_noattention_noaug_best.pth\",\n",
    "    lr=LR\n",
    ")"
   ],
   "id": "eb2b4250cd798311"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "compy12",
   "language": "python",
   "display_name": "Python (Compy12)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
